{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opt_switching_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOvV9aZ7nD6fCbqfLkvLP7o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_stopping-switching/blob/main/opt_switching_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we fix the final regime of the process"
      ],
      "metadata": {
        "id": "1sjUHwhxLQUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, P)$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t = b_{I_t}X_tdt + \\sigma_{I_t}X_tdW_t\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian motion on a filtered probability space $(\\Omega, \\mathcal{F}, \\mathbf{F}=(\\mathcal{F}_t)_{t \\geq 0} P)$ and $I_t$ is the indicator variable of the regimes valued in $\\mathbf{I}_d = \\{1, \\ldots, d \\}$. $b_i \\in \\mathbf{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$ once in regime $I_t=i$ at time $t$.\n",
        "\n",
        "We will consider a discrete approximization (Euler schema) with respect to. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "X^p_{n,i} = \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\sigma^2_i /2)_{\\mathbf{I}}\\Delta t + \\sigma_{i, \\mathbf{I}} \\sqrt{\\Delta t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\Delta t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ],
      "metadata": {
        "id": "sNSqonJN66zF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QsjSbJxO9nQV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackScholes:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths, self.assets ))\n",
        "\n",
        "    spot_paths[0, :, :] = self.spot\n",
        "    random_numbers = np.random.normal(0, 1, (self.periods, paths, self.assets ))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1), self.assets, axis=2)\n",
        "    sig = np.ones((self.periods, paths, self.assets))*self.sigma\n",
        "    \n",
        "    spot_paths[1:, :,  :] = np.repeat(\n",
        "        spot_paths[0:1, :, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])\n",
        "\n",
        "\n",
        "'''\n",
        "PLOT\n",
        "'''\n",
        "\n",
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()"
      ],
      "metadata": {
        "id": "kRvtM2Fl9qTd"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We employ a neural network to approximate the stopping decision functions $\\{f_n\\}_{n=0}^N$ by constructing a sequence of neural networks of the form $f^{\\theta_n}:\\mathbb{R}^d → \\{0,1\\}$ with parameters $\\theta_n \\in \\mathbb{R}^q$ to approximate $f_n$.\n",
        "\n",
        "\n",
        "In its basic form, a neural network is composed of several layers, and layers are made of nodes. From the picture below, we can observe that a node combines input from the data, $x_{1:n}$, with a set of weights, $w_{1:n}$, that either amplify or dampen that input, thereby assigning significance to inputs with regard to the task the algorithm is trying to learn. $x_{1:n}$ are either the inputs of the overall network if this node is in the first layer or the outputs from the previous layer. Then, the input-weight products are summed, usually with a bias term, and the sum is passed through a node’s so-called activation function $f$, to determine whether and to what extent that signal should progress further through the network to affect the ultimate outcome (depending on the magnitude of each associated weight $w_i$). If the signals passes through, we can say that the neuron has been “activated” and returns an output.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1rButBJka1QjKsLSrAWgJKrxNCGdntf-K)\n",
        "\n",
        "Generally, NNs comprise multiple node layers through which data is passed, giving rise to what can be referred to as the depth of a neural network. In such networks, each layer of nodes trains on a distinct set of features based on the previous layer’s output. The further we move into the neural net, the more complex the features can be recognized by the nodes, since they aggregate and recombine features from the previous layer.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1b8Hbzn5xahE9jHf5jgIslG3dedkLAHst)\n",
        "\n",
        "The neural network used here takes the form $F^{\\theta}: \\mathbb{R}^d → (0,1)$ for $\\theta \\in \\{\\theta_0, \\ldots, \\theta_N  \\}$, that is the parameters are trained via a neural network that outputs probabilities in the interval $(0,1)$. This is due to the fact that the G-B optimization algorithm is to be applied to a continuous function with respect to $\\theta_n$, which $f^{\\theta_n}$ is not. Hence, the multi-layer, feed-forward neural network takes the form:\n",
        "\n",
        "\\begin{equation}\n",
        "F^{\\theta}= \\psi \\circ a_3^{\\theta} \\circ \\phi_{q_2} \\circ a_2^{\\theta} \\circ \\phi_{q_1} \\circ a_1^{\\theta}\n",
        "\\end{equation}\n",
        "where \n",
        "\n",
        "-  $q_1, q_2$ are the number of nodes in the hidden layers\n",
        "- $a_1^{\\theta} : \\mathbb{R}^d → \\mathbb{R}^{q_1}, a_2^{\\theta}: \\mathbb{R}^{q_1} → \\mathbb{R}^{q_2}$ are linear transformation functions: $a_i^{\\theta}(x)=W_i x + b_i$ with matrices $W_1 \\in \\mathbb{R}^{q_1 \\times d}, W_2 \\in \\mathbb{R}^{q_2 \\times q_1}, W_3 \\in \\mathbb{R}^{q_2 \\times 1}$ and vectors $b_1 \\in \\mathbb{R}^{q_1}, b_2 \\in \\mathbb{R}^{q_2}, b_3 \\in \\mathbb{R}^{1}$.\n",
        "- $\\phi_{q_i}: \\mathbb{R}^{q_i}$ is the ReLU activation function: $\\phi_{q_1}(x_i, \\ldots, x_{q_i})=(x_i^{+}, \\ldots, x_{q_i}^{+})$\n",
        "- $\\psi = \\mathbb{R} → \\mathbb{R}$ is the logistic sigmoid function: $\\psi(x)=1/(1+ e^{-x})$.\n",
        "Between the layers a batch normalization is also added, it takes the output from the previous layer and normalizes it before sending it to the next layer. This has the effect of stabilizing the neural network. \n",
        "\n",
        "The parameters will comprise $\\theta = \\{W_1, W_2,, W_3, b_1, b_2, b_3\\}\\in \\mathbb{R}^q$, where $q=q_1(d+q_2+1)+2q_2+1$. The value of $d$ stands for the dimension, that is the number of assets and will be varied among $d=\\{2,4, 5, 10, 20\\}. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MbI9kTmBCcAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = assets + 40\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.a1 = nn.Linear(assets, H)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.bn0(input)\n",
        "    out = self.a1(input)\n",
        "\n",
        "    out = self.relu(out)\n",
        "    out = self.bn1(out)\n",
        "\n",
        "    out = self.a2(out)\n",
        "    \n",
        "    #out = self.relu(out)\n",
        "    #out = self.bn2(out)\n",
        "    out = self.a3(out)\n",
        "    \n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    torch.nn.init.zeros_(m.weight)\n",
        "    #torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "p94V2uI-CC86"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training_network(object):\n",
        "\n",
        "  def __init__(self, assets, epochs = 400, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    \n",
        "    # transform data into tensors \n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double()\n",
        "\n",
        "    self.network.train(True)\n",
        "    ones = torch.ones(len(future_payoff))\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(True):\n",
        "        outputs = self.network.forward(X_inputs).reshape(-1) \n",
        "        reward = (current_payoff.reshape(-1) * outputs ) +future_payoff * (ones - outputs) # reward function\n",
        "\n",
        "        # compute loss function\n",
        "        loss = -torch.mean(reward) # loss function\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradients and backpropagate\n",
        "        loss.backward() \n",
        "\n",
        "      # take a step, updating the parameters  \n",
        "      optimizer.step() \n",
        "\n",
        "    torch.save(self.network.state_dict(), 'checkpoint.pth')\n",
        "    return outputs, self.network, losses  \n",
        "\n",
        "  def evaluate_network(self, X_inputs):\n",
        "\n",
        "    # load saved optimized parameters\n",
        "    state_dict = torch.load('checkpoint.pth')\n",
        "    \n",
        "    # impose \"evaluation\" mode\n",
        "    self.network.eval()\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()).detach().numpy(), self.network"
      ],
      "metadata": {
        "id": "ts0bQ6QyCHOk"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Profit_training:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "    self.model = model\n",
        "    \n",
        "\n",
        "  def terminal(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def g(self, date,path,X):\n",
        "    max1=np.max(X[int(date) , path , : ]-self.strike)\n",
        "    return np.exp(-self.model.drift*self.model.dt*date)*np.max(max1,0) \n",
        " \n",
        "\n",
        "  def running(self, Y, X):\n",
        "    gamma = np.array([self.terminal(X) + 0.7, -self.terminal(X)]) # there are two rows, the first for \\gamma_{0,1}, the second for \\gamma_{1,0}\n",
        "    r_benefit = self.terminal(X)\n",
        "    return r_benefit+Y-gamma \n",
        " \n",
        "class Profit_testing:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "    self.model = model\n",
        "\n",
        "  def terminal(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)  \n",
        "\n",
        "  def g(self, date,path,X):\n",
        "    max1=np.max(X[date , path , : ]-self.strike)\n",
        "    return np.max(max1,0) \n",
        "\n",
        "\n",
        "  # switch is F_theta_train \n",
        "  def running(self, Y, date, path, S, X, switch, gamma):\n",
        "    val=Y[date+1, path]- gamma  \n",
        "    k = np.array([0.4, 0.7])\n",
        "    r_benefit = self.g(date, path, X)\n",
        "    return val*int(switch[date, path])+r_benefit.numpy()\n",
        "\n",
        "\n",
        "  def current_payoff(self, data, Y, date, regimes, regimepath):\n",
        "    current_p = np.zeros((self.model.paths))\n",
        "    \n",
        "    for m in range(0, self.model.paths - 1):\n",
        "        value = Y[date+1, m]\n",
        "        running_benefit = self.g(date, m, data)      \n",
        "        old_regime = int(regimepath[date +1, m])     \n",
        "        current_regime = int(regimes[~old_regime])\n",
        "\n",
        "        \n",
        "        if (old_regime - current_regime)>0:          #gamma 0-1\n",
        "          gamma = self.g(date, m, data)**0.3+np.random.normal(0,1,1) + value\n",
        "        \n",
        "        else: gamma = - self.g(date, m, data) + value #gamma 1-0  \n",
        "        current_p[m] = gamma + running_benefit\n",
        "        #current_p[m] = gamma + running_benefit\n",
        "            \n",
        "    return current_p\n",
        "\n",
        "  def current_payoff_trained(self, data, Y, date, regimes, regime_path, which): \n",
        "    current_p = np.zeros((self.model.paths))\n",
        "    for m in range(0, self.model.paths - 1):\n",
        "      running_benefit = self.g(date, m, data) \n",
        "      old_regime = int(regime_path[date +1, m])\n",
        "      value = Y[date+1, m]\n",
        "      \n",
        "      if int(which[m])==1:\n",
        "        regime_path[date, m] = regimes[~old_regime]\n",
        "        current_regime = regime_path[date, m]\n",
        "        if (old_regime - current_regime)>0:          \n",
        "          gamma = self.g(date, m, data)**0.3+np.random.normal(0,1,1) + value #gamma 0-1\n",
        "        else: \n",
        "          gamma = - self.g(date, m, data) + value #gamma 1-0  \n",
        "      else:\n",
        "        regime_path[date, m]=int(regimes[~old_regime])\n",
        "        gamma = 0\n",
        "      current_p[m] = gamma + running_benefit\n",
        "    return current_p\n",
        "    "
      ],
      "metadata": {
        "id": "4vdhJjVlyJbF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Currently, the parameters $F^{\\theta}$ are found by maximizing the reward function that takes as inputs:\n",
        "- current payoff: a payoff that considers both possibilities of switching or not at that timestep (as we dont know theta yet)\n",
        "- future payoff (same thing)\n",
        "\n",
        "\n",
        "possibly not a good idea, instead:\n",
        "- future payoff could consider both cases only for N-1\n",
        "- current payoff probably should stay as it is"
      ],
      "metadata": {
        "id": "BN1DV9Hcvqha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "  def __init__(self, model, payoff):\n",
        "\n",
        "    self.model = model    \n",
        "    self.neural_stopping = Training_network(self.model.assets, 400) \n",
        "    self.payoff = Profit_testing(self.model)\n",
        "\n",
        "  def value(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    \n",
        "    # create empty objects to store values\n",
        "    regimes = [0, 1]\n",
        "    regime_path=np.zeros((model.periods+1, model.paths)) # record at which regime we're at at each n\n",
        "    Y_train=np.zeros((model.periods+1, model.paths))\n",
        "    F_theta_train=np.zeros((model.periods+1,model.paths)) # record switching events for each n\n",
        "    mods=[None]*model.periods # record the models of the NN for testing\n",
        "    loss_functions = [None]*model.periods\n",
        "\n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.terminal(stock_paths[-1, :, :])   # payoff of the last date for each path.\n",
        "    Y_train[model.periods, :]= final_payoff\n",
        "    F_theta_train[model.periods,:]=1 # at maturity we switch \n",
        "    regime_path[model.periods, :] = random.sample(regimes, 1)[0] # sample a regime at maturity\n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \",\", model.paths)\n",
        "\n",
        "    # before maturity\n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1): \n",
        "      current_payoff = self.payoff.current_payoff(data = stock_paths, \n",
        "                                               Y = Y_train, date = date, \n",
        "                                               regimes = regimes,\n",
        "                                               regimepath = regime_path)\n",
        "\n",
        "      stopping_probability, networks, loss = self.neural_stopping.train_network(stock_paths[date, : , :], \n",
        "                                                    current_payoff,\n",
        "                                                    final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "\n",
        "      \n",
        "      \n",
        "      print(\"date\", date, \",\", len([1 for l in stopping_probability if l > 0.5]), \" mean loss \", np.mean(loss))\n",
        "      F_theta_train[date,:]=(stopping_probability > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "      which = stopping_probability > 0.5\n",
        "      immediate_exercise_value = self.payoff.current_payoff_trained(stock_paths, Y_train, date, regimes, regime_path, which)\n",
        "\n",
        "\n",
        "      values[which] = immediate_exercise_value[which] # when we switch we take the current profit\n",
        "      values[~which] *= np.math.exp((-model.drift) * ((model.periods-date)/model.periods))           # when we don't switch we take final profit discounted \n",
        "      Y_train[date, :] = values\n",
        "\n",
        "      mods[date]=networks \n",
        "      loss_functions[date]=loss    \n",
        "    \n",
        "    return mods, loss_functions\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  def stop(self, stock_values, current_payoff,\n",
        "           future_payoff):\n",
        "    \n",
        "    self.neural_stopping.train_network(\n",
        "      stock_values,\n",
        "      current_payoff ,\n",
        "      future_payoff)\n",
        "\n",
        "    inputs = stock_values\n",
        "    stopping_probability , networks   = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability , networks  \n"
      ],
      "metadata": {
        "id": "7UvqI1aXKWAL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate paths Y\n",
        "# goal of this phase is to be able to get stopping decisions f_theta_n\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':200, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_train=BlackScholes(**hyperparam_training)\n",
        "\n",
        "\n",
        "pricing = Training(S_train, Profit_testing)\n",
        "'''\n",
        "arguments are:\n",
        "- path process\n",
        "- Profit testing classes\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "mods, functions = pricing.value()\n"
      ],
      "metadata": {
        "id": "sp-KE2XpKsKY",
        "outputId": "64d9dd1b-1e1e-422d-a2e6-ba2f2b1a3b0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 9 , 200\n",
            "date 8 , 200  mean loss  -49.30812378788405\n",
            "date 7 , 200  mean loss  -52.5425964509862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 6 , 0  mean loss  nan\n",
            "date 5 , 0  mean loss  nan\n",
            "date 4 , 0  mean loss  nan\n",
            "date 3 , 0  mean loss  nan\n",
            "date 2 , 0  mean loss  nan\n",
            "date 1 , 0  mean loss  nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = list(filter(None, functions))\n",
        "legend = [\"n = 1\", \"n = 2\", \"n = 3\", \"n = 4\", \"n = 5\", \"n = 6\", \"n = 7\", \"n = 8\"]\n",
        "\n",
        "for i in range(len(filtered_list)):\n",
        "  epochs = np.array([i for i in range(len(filtered_list[0]))])\n",
        "  plt.plot(epochs, filtered_list[i], label='loss funciton')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend(legend)\n",
        "  plt.title('Loss curves across time periods')\n",
        "  plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yVXeiEjqrfRf",
        "outputId": "1fd809ca-6110-4ac7-80b2-11b609311158"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':200, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "model=BlackScholes(**hyperparam_training)\n",
        "\n",
        "neural_stopping = Training_network(model.assets, model.paths) \n",
        "profit_testing = Profit_testing(model)\n",
        "stock_paths = model.simulate_process() \n",
        "print(stock_paths.shape)   \n",
        "    \n",
        "# create empty objects to store values\n",
        "regimes = [0, 1]\n",
        "regime_path=np.zeros((model.periods+1, model.paths)) # record at which regime we're at at each n\n",
        "Y_train=np.zeros((model.periods+1, model.paths))\n",
        "F_theta_train=np.zeros((model.periods+1,model.paths)) # record switching events for each n\n",
        "mods=[None]*model.periods # record the models of the NN for testing\n",
        "loss_functions = [None]*model.periods\n",
        "\n",
        "# at maturity N\n",
        "final_payoff = profit_testing.terminal(stock_paths[-1, :, :])   # payoff of the last date for each path.\n",
        "Y_train[model.periods, :]= final_payoff\n",
        "F_theta_train[model.periods,:]=1 # at maturity we switch \n",
        "regime_path[model.periods, :] = random.sample(regimes, 1)[0] # sample a regime at maturity\n",
        "values = final_payoff # keep????\n",
        "\n",
        "print(\"final_payoff\", final_payoff)\n",
        "print(regime_path[model.periods, :])"
      ],
      "metadata": {
        "id": "RbFW9rKM1kH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fbc54fe-9d52-4940-c341-2692cbe001dd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10, 200, 2)\n",
            "final_payoff [10.98600992 14.81381564 12.87700921 15.82391062 21.11664233 31.87055689\n",
            " 21.19031527 21.04666735 20.9061203  21.07695362 37.67299294 29.24155337\n",
            " 18.88117309 21.75476083 20.47130872 38.6138585  20.10831038 26.92050306\n",
            " 17.04298588 28.90709632 38.33158131 26.66719859 26.91804802 25.9380825\n",
            " 39.11577429 34.75902118 11.06729078 27.60436361 23.669513   27.91356906\n",
            " 19.67412172 28.87008691 26.63319948 21.39344185 25.98981881 21.66579721\n",
            " 30.16466008 19.16711978 34.25328673 23.29270706 11.99253309 11.4647423\n",
            " 27.68461765 39.50010452 22.49165129 25.44478261 33.37520218 27.89507247\n",
            " 42.34559934 30.53302253 18.69683736  9.0543903  38.31510597 24.40457215\n",
            " 16.6827499  13.68621655 19.10690837 24.63656632 33.21950305 17.10393171\n",
            " 14.6390305  22.19753964 48.33574463 30.29515959 14.84005083 19.82741729\n",
            " 16.73631569 11.76074183 34.52110492 11.90178084 23.82818433 27.23618812\n",
            " 12.32784615 21.09754109 19.04702233 15.42528185 27.24549237 28.80819429\n",
            " 25.79511099 26.29315048 31.63985642 36.86026107 22.63754297 12.27937988\n",
            " 33.52279553 29.93645033 32.40900731 23.18533092  7.52241051 40.44479438\n",
            " 31.62654296 25.33731758 25.24016989 35.82631066 34.12263874 25.29659491\n",
            " 24.24352708 32.0502855  41.89601557 31.37109076 27.10835289 29.09280624\n",
            " 23.19014732 37.25636626 18.36275275 22.56598198 20.82191402 25.45079739\n",
            " 42.53175185 32.1245469  27.01641792 38.08647866 16.32646014 28.12162004\n",
            " 22.50498371 33.31475728 31.03593879 10.05829172 30.92846095 24.84065213\n",
            " 31.36792544 23.38244884 24.24573252 27.18479198 32.51403036 26.40598908\n",
            " 31.39966428 14.07282259 21.0003625  33.31196232 38.6280357  26.39911249\n",
            " 17.25448526 33.00570778 15.78111236 29.11882188 36.66031393 36.91838871\n",
            " 34.10050832 37.23529008 17.27870927 15.80857214 41.51258903 12.37139762\n",
            " 18.85596484 42.53483567 26.7670464  37.96468385 17.12006766 28.67469217\n",
            " 20.40701212 48.91409936 28.40455462 29.97076619 25.93217237 30.43299528\n",
            " 26.18918202 17.31876667 29.6465868  24.52994699 15.49138962 38.92123766\n",
            " 15.60997    34.40420191 33.40391523 38.33682443 39.92453828 33.13450762\n",
            " 27.52054531 23.68324797 26.80960745 30.96077994 20.57289528 18.84437421\n",
            " 41.50929517 20.07051471 44.95557795 36.88824986 24.67932019 30.81410219\n",
            " 27.05634042 42.67821381 12.59132577 30.61458288 27.20438112 25.8540027\n",
            "  9.90524691 33.75987999 21.91667009 22.48618753 21.80656259 31.69424164\n",
            " 16.41761218 30.18368674 30.28905743 40.71525498 29.5221886  30.23817302\n",
            " 22.63314055  9.62486787]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# before maturity\n",
        "date = stock_paths.shape[0] - 2\n",
        "print(date)\n",
        "\n",
        "current_payoff = profit_testing.current_payoff(data = stock_paths, \n",
        "                                               Y = Y_train, date = date, \n",
        "                                               regimes = regimes,\n",
        "                                               regimepath = regime_path)\n",
        "\n",
        "print(\"current_payoff\", current_payoff)\n",
        "# always gives zero, probably something wring about it\n",
        "\n",
        "stopping_probability, networks, loss = neural_stopping.train_network(stock_paths[date, : , :], \n",
        "                                               current_payoff,\n",
        "                                               final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "      \n",
        "\n",
        "plt.plot(loss)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title(\"Learning rate %f\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "7d0TpnOoFLtZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 902
        },
        "outputId": "91e36290-97f3-42cc-c37b-4a188af5a99d"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n",
            "current_payoff [10.98600992 14.81381564 12.87700921 15.82391062 21.11664233 31.87055689\n",
            " 21.19031527 21.04666735 20.9061203  21.07695362 37.67299294 29.24155337\n",
            " 18.88117309 21.75476083 20.47130872 38.6138585  20.10831038 26.92050306\n",
            " 17.04298588 28.90709632 38.33158131 26.66719859 26.91804802 25.9380825\n",
            " 39.11577429 34.75902118 11.06729078 27.60436361 23.669513   27.91356906\n",
            " 19.67412172 28.87008691 26.63319948 21.39344185 25.98981881 21.66579721\n",
            " 30.16466008 19.16711978 34.25328673 23.29270706 11.99253309 11.4647423\n",
            " 27.68461765 39.50010452 22.49165129 25.44478261 33.37520218 27.89507247\n",
            " 42.34559934 30.53302253 18.69683736  9.0543903  38.31510597 24.40457215\n",
            " 16.6827499  13.68621655 19.10690837 24.63656632 33.21950305 17.10393171\n",
            " 14.6390305  22.19753964 48.33574463 30.29515959 14.84005083 19.82741729\n",
            " 16.73631569 11.76074183 34.52110492 11.90178084 23.82818433 27.23618812\n",
            " 12.32784615 21.09754109 19.04702233 15.42528185 27.24549237 28.80819429\n",
            " 25.79511099 26.29315048 31.63985642 36.86026107 22.63754297 12.27937988\n",
            " 33.52279553 29.93645033 32.40900731 23.18533092  7.52241051 40.44479438\n",
            " 31.62654296 25.33731758 25.24016989 35.82631066 34.12263874 25.29659491\n",
            " 24.24352708 32.0502855  41.89601557 31.37109076 27.10835289 29.09280624\n",
            " 23.19014732 37.25636626 18.36275275 22.56598198 20.82191402 25.45079739\n",
            " 42.53175185 32.1245469  27.01641792 38.08647866 16.32646014 28.12162004\n",
            " 22.50498371 33.31475728 31.03593879 10.05829172 30.92846095 24.84065213\n",
            " 31.36792544 23.38244884 24.24573252 27.18479198 32.51403036 26.40598908\n",
            " 31.39966428 14.07282259 21.0003625  33.31196232 38.6280357  26.39911249\n",
            " 17.25448526 33.00570778 15.78111236 29.11882188 36.66031393 36.91838871\n",
            " 34.10050832 37.23529008 17.27870927 15.80857214 41.51258903 12.37139762\n",
            " 18.85596484 42.53483567 26.7670464  37.96468385 17.12006766 28.67469217\n",
            " 20.40701212 48.91409936 28.40455462 29.97076619 25.93217237 30.43299528\n",
            " 26.18918202 17.31876667 29.6465868  24.52994699 15.49138962 38.92123766\n",
            " 15.60997    34.40420191 33.40391523 38.33682443 39.92453828 33.13450762\n",
            " 27.52054531 23.68324797 26.80960745 30.96077994 20.57289528 18.84437421\n",
            " 41.50929517 20.07051471 44.95557795 36.88824986 24.67932019 30.81410219\n",
            " 27.05634042 42.67821381 12.59132577 30.61458288 27.20438112 25.8540027\n",
            "  9.90524691 33.75987999 21.91667009 22.48618753 21.80656259 31.69424164\n",
            " 16.41761218 30.18368674 30.28905743 40.71525498 29.5221886  30.23817302\n",
            " 22.63314055  0.        ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"date\", date, \",\", len([1 for l in stopping_probability if l > 0.5]))\n",
        "print(stopping_probability.shape)\n",
        "F_theta_train[date]=(stopping_probability > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "which = stopping_probability > 0.5\n",
        "immediate_exercise_value = profit_testing.current_payoff_trained(stock_paths, Y_train, date, regimes, regime_path, which)\n",
        "\n",
        "\n",
        "values[which] = immediate_exercise_value[which] # when we switch we take the current profit\n",
        "values[~which] *= np.math.exp((-model.drift) * ((model.periods-date)/model.periods))           # when we don't switch we take final profit discounted \n",
        "Y_train[date, :] = values\n",
        "\n",
        "mods[date]=networks \n",
        "loss_functions[date]=loss\n",
        "\n",
        "\n",
        "\n",
        "print(profit_testing.g(date, 2, stock_paths))\n",
        "print(stock_paths[date, 2, :])\n",
        "max1=np.max(stock_paths[date , 2 , : ])\n",
        "print(np.max(max1,0) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP6ndvxegqoH",
        "outputId": "21ef1688-a3d4-49d3-a547-a01d1c23f087"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 8 , 200\n",
            "torch.Size([200])\n",
            "7.807109024841125\n",
            "[107.80710902 100.1512072 ]\n",
            "107.80710902484113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lower bound\n",
        "\n",
        "the stopping time $\\tau^{\\Theta}$ gives a lower bound $L=\\mathbb{E}g(\\tau^{\\Theta}, X_{\\tau^{\\Theta}})$ for the optimal value $V_0= \\sup_{\\tau \\in \\mathcal{T}}\\mathbb{E}g(\\tau, X_{\\tau})$.\n",
        "\n",
        "Simulate \n",
        "- $K_L = 1024$ paths $(y_n^k)_{n=0}^N$, $k=1, \\ldots, K_L$, of $(X_n)_{n=0}^N$ and assume these are drawn independently from the realizations $(x_n^k)_{n=0}^N$, $k=1, \\ldots, K$.\n",
        "\n",
        "The unbiased estimate of the lower bound $L$ is given by\n",
        "\\begin{equation}\n",
        "\\hat{L}=\\frac{1}{K_L} \\sum_{k=1}^{K_L} g(l^k, y_{l^k}^k)\n",
        "\\end{equation}\n",
        "where $l^k = l(y_0^k, \\ldots, y_{N-1}^k)$"
      ],
      "metadata": {
        "id": "k8JSTFLsNMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Lower bound\n",
        "\n",
        "# sample y from the process (Y)\n",
        "hyperparam_testing_L = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':5000, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':20,  'spot':110,}\n",
        "S_test_L=BlackScholes(**hyperparam_testing_L)\n",
        "\n",
        "# now we can compute all the stopping times recursively"
      ],
      "metadata": {
        "id": "eBdQnHLJNOMj"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "class Testing_Lower:\n",
        "  def __init__(self, model, training, testing, mods):   \n",
        "    self.model = model # argument is S   \n",
        "    self.neural_stopping = Training_network(model.assets, 400) \n",
        "    self.profit_testing = Profit_testing(self.model)\n",
        "    self.mods = mods\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    stock_paths = self.model.simulate_process()\n",
        "    k = np.array([0.4, 0.7])\n",
        "    regimes = [0, 1]\n",
        "    regime_path=np.zeros((model.periods+1, model.paths)) # record at which regime we're at at each n\n",
        "    Y_train=np.zeros((model.periods+1, model.paths))\n",
        "    F_theta_train=np.zeros((model.periods+1,model.paths)) # record switching events for each n\n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = np.array([self.profit_training.terminal(stock_paths[-1, :, :]), self.profit_training.terminal(stock_paths[-1, :, :])])   # payoff of the last date for each path.\n",
        "    future_payoff = torch.from_numpy(final_payoff*(np.math.exp((-model.drift) * model.periods))).double() \n",
        "    Y_train[model.periods, :]= final_payoff[0]\n",
        "    F_theta_train[model.periods,:]=1 # at maturity we switch (does it matter?)\n",
        "    regime_path[model.periods, :] = random.sample(regimes, 1)[0] # sample a regime at maturity\n",
        "    values = Y_train[model.periods, :]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.profit_training.running(Y_train[date+1, :], stock_paths[date, :, :])\n",
        "      mod_curr=self.mods[date]\n",
        "      probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "      np_probs=probs.detach().numpy().reshape(self.model.paths)\n",
        "      \n",
        "      F_theta_train[date,:]=(np_probs > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      for m in range(0,model.paths-1):\n",
        "        old_regime = regime_path[date +1, m]\n",
        "        regime_path[date, m] = int(which[m])\n",
        "        if which[m] == True:\n",
        "          if int(old_regime) - int(which[m])>0:  #gamma 0-1\n",
        "            gamma = self.profit_testing.g(date, m, stock_paths)+0.7\n",
        "          else: gamma = -self.profit_testing.g(date, m, stock_paths) #gamma 1-0  \n",
        "        else:\n",
        "          gamma = 0 \n",
        "        Y_train[date, m] = Y_train[date+1, m]- gamma\n",
        "\n",
        "\n",
        "      immediate_exercise_value = Y_train[date, :]       \n",
        "      values[which] = immediate_exercise_value[which] # when we switch we take the current profit\n",
        "      values[~which] *= ((model.periods-date)/model.periods)           # when we don't switch we take final profit discounted \n",
        "\n",
        "      #Y_train[date, :] = values\n",
        "      print(\"date\", date, round(np.mean(values), 3), len([1 for l in np_probs if l > 0.5]))\n",
        "\n",
        "    \n",
        "    return round(np.mean(values), 3), Y_train\n",
        "\n"
      ],
      "metadata": {
        "id": "PpoI_K_MNO6b"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dict ={}\n",
        " \n",
        "# Insert data into dictionary\n",
        "dict1 = {\n",
        "     1: [\"2\", 90, 97.339, 0.009],\n",
        "     2: [\"2\", 100, 205.426, 0.006],\n",
        "     3: [\"2\", 110, 315.878, 0.007],\n",
        "     7: [\"4\", 90, 130.082, 0.008],\n",
        "     8: [\"4\", 100, 235.951, 0.008],\n",
        "     9: [\"4\", 110, 334.079, 0.005],\n",
        "     10: [\"5\", 90, 134.486, 0.008],\n",
        "     11: [\"5\", 100, 224.051, 0.006],\n",
        "     12: [\"5\", 110, 282.737, 0.006],\n",
        "     13: [\"10\", 90, 158.875, 0.005],\n",
        "     14: [\"10\", 100, 273.452, 0.008],\n",
        "     15: [\"10\", 110, 391.043, 0.015],\n",
        "     16: [\"20\", 90, 100.447, 0.008],\n",
        "     17: [\"20\", 100, 192.448, 0.01],\n",
        "     18: [\"20\", 110, 301.107, 0.009],\n",
        "     }\n",
        " \n",
        "# Print the names of the columns.\n",
        "print (\"{:<10} {:<10} {:<10} {:<10}\".format('assets', 'spot', 'L', 'timeL'))\n",
        " \n",
        "# print each data item.\n",
        "for key, value in dict1.items():\n",
        "    assets, spot, L, timeL = value\n",
        "    print (\"{:<10} {:<10} {:<10} {:<10}\".format(assets, spot, L, timeL))"
      ],
      "metadata": {
        "id": "qsGOwzwDvUCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5fa5b12-d937-458f-ed07-73a8ab68698e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets     spot       L          timeL     \n",
            "2          90         97.339     0.009     \n",
            "2          100        205.426    0.006     \n",
            "2          110        315.878    0.007     \n",
            "4          90         130.082    0.008     \n",
            "4          100        235.951    0.008     \n",
            "4          110        334.079    0.005     \n",
            "5          90         134.486    0.008     \n",
            "5          100        224.051    0.006     \n",
            "5          110        282.737    0.006     \n",
            "10         90         158.875    0.005     \n",
            "10         100        273.452    0.008     \n",
            "10         110        391.043    0.015     \n",
            "20         90         100.447    0.008     \n",
            "20         100        192.448    0.01      \n",
            "20         110        301.107    0.009     \n"
          ]
        }
      ]
    }
  ]
}