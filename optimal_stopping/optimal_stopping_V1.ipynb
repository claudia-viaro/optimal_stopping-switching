{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_stopping-switching/blob/main/optimal_stopping/optimal_stopping_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aX5-o2Sa7nC"
      },
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t^i = (b-\\delta_i)dt + \\sigma_i dW_t^i\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian otion on a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\geq 0}, \\mathbb{P})$ and $b$, $d_i$, $\\sigma_i >0$ are the drift. dividend yield and volatility of the system at time $t$.\n",
        "\n",
        "We will consider a discrete time approximization (Euler schema) on an equidistant time grid $0=t_0 < t_1 < \\ldots < t_N = T$, where $t_n = n \\cdot T/N$. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "x^p_{n,i} = x_{0,i} \\cdot \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\delta_i - \\sigma^2_i /2)\\Delta t + \\sigma_{i} \\sqrt{\\Delta t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\Delta t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "yEZA-EFaBd0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata\n",
        "from google.colab import files\n",
        "import helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "xJbxC0rzBhrT"
      },
      "outputs": [],
      "source": [
        "class BlackScholes:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths, self.assets ))\n",
        "\n",
        "    spot_paths[0, :, :] = self.spot\n",
        "    random_numbers = np.random.normal(\n",
        "        0, 1, (self.periods, paths, self.assets ))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1), self.assets, axis=2)\n",
        "    sig = np.ones((self.periods, paths, self.assets))*self.sigma\n",
        "    #sig = np.repeat(np.repeat(np.repeat(\n",
        "    #    np.reshape(self.sigma, (-1, 1, 1)), self.periods+1, axis=2),\n",
        "    #    paths, axis=1), self.assets, axis=0)\n",
        "    \n",
        "    spot_paths[1:, :,  :] = np.repeat(\n",
        "        spot_paths[0:1, :, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "class GBM:\n",
        "    def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike = 100,dividend=0):\n",
        "        self.maturity = maturity\n",
        "        self.strike = strike\n",
        "        self.assets = assets\n",
        "        self.sigma=sigma *np.ones(self.assets)\n",
        "        self.delta=delta\n",
        "        self.spot = spot*np.ones(self.assets)\n",
        "        self.drift = drift - dividend\n",
        "        self.paths = paths\n",
        "        self.periods = periods\n",
        "        self.dt = self.maturity / self.periods\n",
        "    \n",
        "    def simulate_process(self):\n",
        "        \n",
        "        dt = self.maturity / self.periods\n",
        "        So_vec=self.spot*np.ones((1,S.paths, S.assets))\n",
        "        \n",
        "        Z=np.random.standard_normal((self.periods,self.paths, self.assets))\n",
        "        s=self.spot*np.exp(np.cumsum((self.drift-self.delta-0.5*self.sigma**2)*dt+self.sigma*np.sqrt(dt)*Z, axis=0))\n",
        "        \n",
        "        s=np.append(So_vec, s, axis=0)\n",
        "        return s  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "MpTiRUxLBj5L"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Neural network\n",
        "'''\n",
        "\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = assets + 40\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.a1 = nn.Linear(assets, H)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.bn0(input)\n",
        "    out = self.a1(out)\n",
        "\n",
        "    out = self.relu(out)\n",
        "    #out = self.bn1(out)\n",
        "\n",
        "    #out = self.a2(out)\n",
        "    \n",
        "    #out = self.relu(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.a3(out)\n",
        "    \n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    # torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "FRYgMuM2C_K0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "PAYOFF\n",
        "'''\n",
        "\n",
        "# Payoff\n",
        "class Payoff:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "\n",
        "  def MaxCall(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def MaxPut(self, X):\n",
        "    payoff = self.strike - np.max(X, axis=1)\n",
        "    return payoff.clip(0, None)   \n",
        "\n",
        "\n",
        "  def GeometricPut(self, X):\n",
        "    dim = len(X[1])  \n",
        "    payoff = self.strike - np.prod(X, axis=1) ** (1/dim)\n",
        "    return payoff.clip(0, None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class \"Recursive\"\n",
        "This class contains the main calculations of the algorithm, hence the recursion.\n",
        "\n",
        "### price\n",
        "First we start with some elements:\n",
        "1. we simulate $d$ asset prices $\\{X^i \\}^d_{i=1}$ along $m$ paths according to a geometric Brownian motion process. We consider the iys discretized version on an equidistant time grid, $t_n = n \\cdot T/N$ for $n=0, \\ldots, N$:\n",
        "\\begin{equation} \\tag{7}\n",
        "x_{n,i}^m = x_{0,i} \\cdot \\exp \\Big\\{\\sum_{k=0}^n \\Big((r-\\delta_i - \\sigma_i^2 /2) \\Delta t + \\sigma_i \\sqrt{\\Delta t} \\cdot Z_{k, i}^m  \\Big) \\Big\\}\n",
        "\\end{equation}\n",
        "where $(r-\\delta_i) \\in \\mathbb{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$, $\\Delta t =T/N$ and $Z_{k, i}^m \\sim \\mathcal{N}(0,1)$\n",
        "2. we define the discount factor $\\exp \\{(r-\\delta_i )\\Delta t \\}$\n",
        "\n",
        "\n",
        "Then we can start the recursion:\n",
        "\n",
        "*At maturity $N$*\n",
        "1. we compute the profit at $N$ \"final_payoff\" $(4)$\n",
        "\n",
        "*Before maturity, for each date $ n=N-1, \\ldots, 0$*\n",
        "1. we compute \"current_payoff\" using \"Profit_training.running()\"\n",
        "2. we obtain a stopping rule for each path, using as arguments the current payoff, the discounted final payoff (now called \"values\") and the entire process. Record then the stopping rules in \"F_theta_train\" **[I am not sure about the discounting]**\n",
        "3. we compute $\\check{V}_{n}^i$ according to $(4)$, using \"Payoff.Maxcall()\"  and record it under \"Y_train\". Hence we have a matrix with dimension periods x paths, recording $\\check{V}_{n}^i$\n",
        "5. we compute the mean estimate across paths for each date (Y_test_mean) and the standard error so that we can plot the values with a 95% CI"
      ],
      "metadata": {
        "id": "DkGCjRMDJuP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "v1c9hUTGBzcz"
      },
      "outputs": [],
      "source": [
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Training_network(object):\n",
        "\n",
        "  def __init__(self, assets, paths, epochs=50):\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.epochs = epochs\n",
        "    self.network = Ftheta_NN(self.assets).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "  # training part\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "        \n",
        "    # several optimization methods are available (here Adam algorithm). as argument input the parameters to be optimized    \n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    \n",
        "    # set values for the NN inputs (stock_values) and loss function\n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double() # input to the NN must be a tensor\n",
        "    self.network.train(True) # set training mode ON\n",
        "    ones = torch.ones(len(future_payoff)) # we need a vector of 1's in the loss function\n",
        "    losses = []\n",
        "    for epoch in range(self.epochs):\n",
        "      # set the gradients of all optimized tensors to zero (at every step we start fresh)\n",
        "      optimizer.zero_grad()\n",
        "      with torch.set_grad_enabled(True):\n",
        "        F_theta = self.network.forward((X_inputs)).reshape(-1) # probabilities\n",
        "        reward = (current_payoff.reshape(-1)* F_theta + future_payoff * (ones - F_theta)) \n",
        "        \n",
        "        # compute loss function\n",
        "        loss = -torch.mean(reward)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        # compute gradients\n",
        "        loss.backward()\n",
        "      \n",
        "      # take a step, updating the parameters \n",
        "      optimizer.step()\n",
        "    \n",
        "    torch.save(self.network.state_dict(), 'checkpoint.pth')\n",
        "\n",
        "    return F_theta, self.network, losses  \n",
        "  \n",
        "  # function to inform the NN to perform a testing phase\n",
        "  def evaluate_network(self, X_inputs):\n",
        "    state_dict = torch.load('checkpoint.pth')\n",
        "    self.network.load_state_dict(state_dict)\n",
        "\n",
        "    self.network.eval()\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    \n",
        "    # the output is a probability for each date and path\n",
        "    # it is obtained by feeding the NN with the dimension of the assets (at a specific date for all paths), \n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()).detach().numpy()\n"
      ],
      "metadata": {
        "id": "ZbIYQqM3bKnb"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training\n",
        "\n",
        "We conduct $3000+d$ training steps and for each we generate a batch of $8192$ paths of $(X_n)_{n=0}^N$.\n",
        "\n",
        "The resulting output will be the stopping decisions $f^{\\theta_n}$\n"
      ],
      "metadata": {
        "id": "F67WgZCjmvmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate paths Y\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':2000, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':10,  'spot':90,}\n",
        "S_train=BlackScholes(**hyperparam_training)\n"
      ],
      "metadata": {
        "id": "67CEvqrDYbYI"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "  def __init__(self, model, payoff_function):\n",
        "\n",
        "    self.model = model\n",
        "    self.payoff = payoff_function(self.model)\n",
        "    self.neural_stopping = Training_network(self.model.assets, self.model.paths)\n",
        "\n",
        "  def value(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    mods=[None]*model.periods # record the models of the NN for testing\n",
        "    loss_functions = [None]*model.periods\n",
        "    \n",
        "    \n",
        "    # AT MATURITY N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    print(\"date\", model.periods, \",\", model.paths)\n",
        " \n",
        "\n",
        "    # from n=N-1 to 0 with steps of -1\n",
        "\n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):      \n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      stopping_rule , networks, loss = self.neural_stopping.train_network(stock_paths[date, : , :], \n",
        "                                                  current_payoff,\n",
        "                                                  final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "      mods[date]=networks\n",
        "      loss_functions[date]=loss\n",
        "      print(\"date\", date, \",\", len([1 for l in stopping_rule if l > 0.5]), \" mean loss \", np.mean(loss))\n",
        "\n",
        "\n",
        "    return mods, loss_functions\n",
        "\n",
        "  def stop(self, stock_values, current_payoff, future_payoff, train=True):\n",
        "    if train:\n",
        "      stopping_probability, networks, losses = self.neural_stopping.train_network(stock_values,\n",
        "                                                                          current_payoff,\n",
        "                                                                          future_payoff)\n",
        "      #inputs = stock_values\n",
        "      #stopping_probability , networks   = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability, networks, losses  "
      ],
      "metadata": {
        "id": "T6mxhgqPaQj5"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing = Training(S_train, Payoff)\n",
        "mods, loss_function = pricing.value()"
      ],
      "metadata": {
        "id": "2XEhZY0obdbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61620685-4f10-4e48-d954-881ed952beba"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 9 , 2000\n",
            "date 8 , 569  mean loss  -35.551161136532784\n",
            "date 7 , 336  mean loss  -33.95588337460426\n",
            "date 6 , 92  mean loss  -33.40578030288877\n",
            "date 5 , 0  mean loss  -33.91814081013949\n",
            "date 4 , 0  mean loss  -33.93614483344813\n",
            "date 3 , 0  mean loss  -33.44514653051972\n",
            "date 2 , 0  mean loss  -32.792822994212116\n",
            "date 1 , 0  mean loss  -32.09536271264336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = list(filter(None, loss_function))\n",
        "legend = [\"n = 1\", \"n = 2\", \"n = 3\", \"n = 4\", \"n = 5\", \"n = 6\", \"n = 7\", \"n = 8\"]\n",
        "\n",
        "for i in range(len(filtered_list)):\n",
        "  epochs = np.array([i for i in range(len(filtered_list[0]))])\n",
        "  plt.plot(epochs, filtered_list[i], label='loss funciton')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend(legend)\n",
        "  plt.title('Loss curves across time periods')\n",
        "  plt.plot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "6IewJAQSf8OT",
        "outputId": "5259ee5b-d94c-420e-a8f1-c38bd698bd15"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "53elhfVnl60H"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# CHECK TRAINING\n",
        "\n",
        "# check training\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':10, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "model=BlackScholes(**hyperparam_training)\n",
        "payoff = Payoff(model)\n",
        "stock_paths = model.simulate_process()    \n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "mods=[None]*model.periods\n",
        "    \n",
        "    \n",
        "# AT MATURITY N\n",
        "final_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "future_payoff = torch.from_numpy(final_payoff).double() # better discounting\n",
        "values = final_payoff  \n",
        "\n",
        "# recursive calc. before maturity\n",
        "date = stock_paths.shape[0] - 2\n",
        "current_payoff =  payoff.MaxCall(stock_paths[date, :, :])\n",
        "current_payoff = torch.from_numpy(current_payoff).double()\n",
        "future_payoff = torch.from_numpy(values*disc_factor).double()\n",
        "X_inputs = torch.from_numpy(stock_paths[date, : , :]).double() # input to the NN must be a tensor\n",
        "\n",
        "# check function stop\n",
        "#stopping_rule , networks= stop(stock_paths[date, : , :],  current_payoff, values*disc_factor)\n",
        "#mods[date]=networks\n",
        "\n",
        "# check function training_network\n",
        "#neural_stopping = Training_network(model.assets, model.paths)\n",
        "#neural_stopping.train_network(stock_paths[date, : , :], current_payoff , values*disc_factor)\n",
        "\n",
        "network = Ftheta_NN(model.assets)\n",
        "network.apply(init_weights).double()\n",
        "\n",
        "optimizer = optim.Adam(network.parameters())\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "\n",
        "network.train(True) # set training mode ON\n",
        "ones = torch.ones(len(future_payoff), requires_grad=True) # we need a vector of 1's in the loss function\n",
        "losses = []\n",
        "for epoch in range(5000):\n",
        "  optimizer.zero_grad()\n",
        "  with torch.set_grad_enabled(True):\n",
        "    F_theta = network(X_inputs)   #.reshape(-1) # probabilities\n",
        "    reward = (current_payoff.reshape(-1)[0] * F_theta + future_payoff * (ones - F_theta)) \n",
        "    Y = torch.rand([2, 10]).double()\n",
        "    # compute loss function\n",
        "    loss = -torch.mean(reward)\n",
        "    losses.append(loss.item())\n",
        "    #loss = criterion(Y, F_theta)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "plt.plot(losses)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.title(\"Learning rate %f\")\n",
        "plt.show()\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "5oB2_W0Yi5p6",
        "outputId": "30c2c020-3c18-48f1-a5cd-080a8b8b4c74"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# CHECK TRAINING\\n\\n# check training\\nhyperparam_training = {\\'drift\\': 0.2, \\'sigma\\': 0.05, \\'delta\\': 0.1,  \\'paths\\':10, \\'periods\\': 9, \\'maturity\\': 3., \\'strike\\' : 100,\\'assets\\':2,  \\'spot\\':90,}\\nmodel=BlackScholes(**hyperparam_training)\\npayoff = Payoff(model)\\nstock_paths = model.simulate_process()    \\ndisc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\\nmods=[None]*model.periods\\n    \\n    \\n# AT MATURITY N\\nfinal_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\\nfuture_payoff = torch.from_numpy(final_payoff).double() # better discounting\\nvalues = final_payoff  \\n\\n# recursive calc. before maturity\\ndate = stock_paths.shape[0] - 2\\ncurrent_payoff =  payoff.MaxCall(stock_paths[date, :, :])\\ncurrent_payoff = torch.from_numpy(current_payoff).double()\\nfuture_payoff = torch.from_numpy(values*disc_factor).double()\\nX_inputs = torch.from_numpy(stock_paths[date, : , :]).double() # input to the NN must be a tensor\\n\\n# check function stop\\n#stopping_rule , networks= stop(stock_paths[date, : , :],  current_payoff, values*disc_factor)\\n#mods[date]=networks\\n\\n# check function training_network\\n#neural_stopping = Training_network(model.assets, model.paths)\\n#neural_stopping.train_network(stock_paths[date, : , :], current_payoff , values*disc_factor)\\n\\nnetwork = Ftheta_NN(model.assets)\\nnetwork.apply(init_weights).double()\\n\\noptimizer = optim.Adam(network.parameters())\\ncriterion = nn.MSELoss()\\n\\n\\nnetwork.train(True) # set training mode ON\\nones = torch.ones(len(future_payoff), requires_grad=True) # we need a vector of 1\\'s in the loss function\\nlosses = []\\nfor epoch in range(5000):\\n  optimizer.zero_grad()\\n  with torch.set_grad_enabled(True):\\n    F_theta = network(X_inputs)   #.reshape(-1) # probabilities\\n    reward = (current_payoff.reshape(-1)[0] * F_theta + future_payoff * (ones - F_theta)) \\n    Y = torch.rand([2, 10]).double()\\n    # compute loss function\\n    loss = -torch.mean(reward)\\n    losses.append(loss.item())\\n    #loss = criterion(Y, F_theta)\\n    \\n    loss.backward()\\n    optimizer.step()\\n\\nplt.plot(losses)\\nplt.ylabel(\\'loss\\')\\nplt.xlabel(\\'epoch\\')\\nplt.title(\"Learning rate %f\")\\nplt.show()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lower bound\n",
        "\n",
        "the stopping time $\\tau^{\\Theta}$ gives a lower bound $L=\\mathbb{E}g(\\tau^{\\Theta}, X_{\\tau^{\\Theta}})$ for the optimal value $V_0= \\sup_{\\tau \\in \\mathcal{T}}\\mathbb{E}g(\\tau, X_{\\tau})$.\n",
        "\n",
        "Simulate \n",
        "- $K_L = 1024$ paths $(y_n^k)_{n=0}^N$, $k=1, \\ldots, K_L$, of $(X_n)_{n=0}^N$ and assume these are drawn independently from the realizations $(x_n^k)_{n=0}^N$, $k=1, \\ldots, K$.\n",
        "\n",
        "The unbiased estimate of the lower bound $L$ is given by\n",
        "\\begin{equation}\n",
        "\\hat{L}=\\frac{1}{K_L} \\sum_{k=1}^{K_L} g(l^k, y_{l^k}^k)\n",
        "\\end{equation}\n",
        "where $l^k = l(y_0^k, \\ldots, y_{N-1}^k)$"
      ],
      "metadata": {
        "id": "u6ULiVMClRqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Lower bound\n",
        "\n",
        "# sample y from the process (Y)\n",
        "hyperparam_testing_L = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':40, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_test_L=BlackScholes(**hyperparam_testing_L)\n",
        "\n",
        "# now we can compute all the stopping times recursively"
      ],
      "metadata": {
        "id": "fFwBlDkLbnxg"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "model = S_test_L\n",
        "stock_paths = model.simulate_process()\n",
        "date = stock_paths.shape[0] - 2\n",
        "\n",
        "mod_curr = mods[date]     \n",
        "probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "np_probs=probs.detach().numpy().reshape(model.paths)     \n",
        "which = np_probs > 0.5\n",
        "print(which)\n",
        "\n",
        "neural_stopping = Training_network(model.assets, model.paths)\n",
        "stopping_probability , networks   = neural_stopping.evaluate_network(stock_paths[date])\n",
        "print(stopping_probability  > 0.5)\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "MW7B4vELqcXd",
        "outputId": "50387a8c-b258-451b-e478-3b0f3543258e"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nmodel = S_test_L\\nstock_paths = model.simulate_process()\\ndate = stock_paths.shape[0] - 2\\n\\nmod_curr = mods[date]     \\nprobs=mod_curr(torch.from_numpy(stock_paths[date])) \\nnp_probs=probs.detach().numpy().reshape(model.paths)     \\nwhich = np_probs > 0.5\\nprint(which)\\n\\nneural_stopping = Training_network(model.assets, model.paths)\\nstopping_probability , networks   = neural_stopping.evaluate_network(stock_paths[date])\\nprint(stopping_probability  > 0.5)\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "class Testing_Lower:\n",
        "  def __init__(self, model, payoff):   \n",
        "    self.model = model # argument is S   \n",
        "    self.payoff = payoff(self.model)\n",
        "    self.neural_stopping = Training_network(self.model.assets, self.model.paths)\n",
        "\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model    \n",
        "    stock_paths = self.model.simulate_process()\n",
        "    \n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    payoff_0 = self.payoff.MaxCall(stock_paths[0, :, :])  \n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \":\", 1,\" , \", 1, \" , \", model.paths, \"value\", np.mean(values))\n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      #mod_curr=self.mods[date]\n",
        "\n",
        "      probs = self.neural_stopping.evaluate_network(stock_paths[date, : , :])\n",
        "      \n",
        "      #probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "      #np_probs=probs.detach().numpy().reshape(self.model.paths)     \n",
        "\n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      values[which] = current_payoff[which]\n",
        "      values[~which] *= (np.math.exp((-model.drift) * (model.periods-date)/model.periods))\n",
        "      print(\"date\", date, \":\", round(np.min(np_probs), 3),\" , \", round(np.max(np_probs), 3), \" , \", len([1 for l in np_probs if l > 0.5]), \"value\", np.mean(values))\n",
        "\n",
        "    \n",
        "    return round(payoff_0[0], 3), round(np.mean(values)*(np.math.exp((-model.drift) * (date/model.periods))) , 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "aNegNcskb5gl"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_testing = Testing_Lower(S_test_L, Payoff, mods)\n",
        "\n",
        "Y_test_mean, MC_estimate = price_testing.price()\n",
        "print(Y_test_mean, MC_estimate)"
      ],
      "metadata": {
        "id": "1oRLovDLcEwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "b824234a-b28f-4121-ae18-e8ceab234c5c"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-119-7c1fc35261ea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprice_testing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTesting_Lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_test_L\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPayoff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmods\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mY_test_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMC_estimate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprice_testing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMC_estimate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() takes 3 positional arguments but 4 were given"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upper Bound\n",
        "\n",
        "For every $(\\mathcal{F}_n)$-martingale $(M_n)_{n=0}^N$ starting from $0$ and each sequence of integrable error terms $(\\epsilon_n)_{m=0}^N$ satisfying $\\mathbb{E}[\\epsilon_n | \\mathcal{F}_n]=0$ for all $n$, the following expression provides an upper bound for $V_0$, which is also tight if $M=M^H$ and $\\epsilon \\equiv 0$.\n",
        "\\begin{equation}\n",
        "U = \\mathbb{E} \\Big[ \\max_{0 \\leq n \\leq N} [g(n, X_n) - M_n^{\\Theta} - \\epsilon_n ]  \\Big]\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "We need an expression for $M^H$ and use the Doob-Meyer decomposition on the Snell envelope of the reward process:\n",
        "\\begin{equation}\n",
        "H_n = \\text{ess} \\sup_{\\tau \\in \\mathcal{T}_n} \\mathbb{E}[g(\\tau)| \\mathcal{F}_n], \\;\\;\\;\\ n=0, 1, \\ldots, N\n",
        "\\end{equation}\n",
        "where its Doob-Meyer deomposition is given by:\n",
        "\\begin{equation}\n",
        "H_n = H_0 + M_n^H - A_n^H\n",
        "\\end{equation}\n",
        "and\n",
        "\\begin{equation}\n",
        "M_0^H = 0\\;\\;\\;\\; \\text{and} \\;\\; M_n^H-M_{n-1}^H=H_n-\\mathbb{E}[H_n | \\mathcal{F}_{n-1}], \\;\\;\\; n=1, \\ldots, N\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "We use $\\tau^{\\Theta}$ to construct a martingale close to $M^H$. The martingale part of $(H_n^{\\Theta})_{n=0}^N$ is given by:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "&M_0^{\\Theta}\\\\\n",
        "&M_N^{\\Theta}- M_{n-1}^{\\Theta} = H_n^{\\Theta}-\\mathbb{E}[H_n^{\\Theta} | \\mathcal{F}_{n-1}] = f^{\\theta_n}(X_n)g(n, X_n) + (1- f^{\\theta_n})) C_n^{\\Theta}-C_{n-1}^{\\Theta}, \\;\\; n \\geq 1\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "and the continuation value is:\n",
        "\\begin{equation}\n",
        "C_n^{\\Theta}=\\mathbb{E}[g(\\tau_{n+1}^{\\Theta}, X_{\\tau_{n+1}^{\\Theta}})| \\mathcal{F}_n] = \\mathbb{E}[g(\\tau_{n+1}^{\\Theta}, X_{\\tau_{n+1}^{\\Theta}})| X_n], \\;\\;\\;\\ n=0, 1, \\ldots, N-1\n",
        "\\end{equation}\n",
        "there is no need to specify $C_N^{\\Theta}$ because $(1- f^{\\theta_N}(X_N))$ is always $0$.\n",
        "\n",
        "\n",
        "Simulate \n",
        "- $K_U = 1024$ paths $(z_n^k)_{n=0}^N$, $k=1, \\ldots, K_U$, of $(X_n)_{n=0}^N$\n",
        "- $K_U \\times J$ realizations $(v_n^{k,j})_{n=0}^N$, $k=1, \\ldots, K_U$, $j=1, \\ldots, J$, of $(W_{t_n} - W_{t_n - 1})_{n=1}^N$ with $J=16384$\n",
        "- for all $n$ and $k$, generate the $i$-th component of the $j$-th continuation path departing from  $z_n^k$ according to:\n",
        "\\begin{equation}\n",
        "\\tilde{z}_n^{i,k,j}=z_n^{i,k} \\exp \\Big([r- \\delta_i - \\sigma_i^2 /2] (m-n)\\Delta t + \\sigma_i [v_{n+1}^{i,k,j} + \\ldots, v_{m}^{i,k,j}]  \\Big), \\;\\;\\;\\; m=n+1, \\ldots, N\n",
        "\\end{equation}\n",
        "we assume that $\\tilde{z}_{n+1}^{k,j}, \\ldots, \\tilde{z}_{N}^{k,j}$ are conditionally independent of each other and of $z_{n+1}^{k}, \\ldots, z_{N}^{k}$ \n"
      ],
      "metadata": {
        "id": "ffDydd-UaBXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Upper bound\n",
        "\n",
        "# sample Z from the process (X)\n",
        "hyperparam_testing_U = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':1024, 'periods': 4, 'maturity': 3., 'strike' : 100,'assets':1,  'spot':90,}\n",
        "S_test_U=BlackScholes(**hyperparam_testing_U)\n",
        "stock_paths = S_test_U.simulate_process()\n",
        "print(stock_paths.shape) #(5, 1024, 1)"
      ],
      "metadata": {
        "id": "vSpdEj0XXLuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to generate v values\n",
        "\n",
        "class Zvalues:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths))\n",
        "\n",
        "    spot_paths[0, :] = self.spot\n",
        "    random_numbers = np.random.normal(\n",
        "        0, 1, (self.periods, paths))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1)\n",
        "    sig = np.ones((self.periods, paths))*self.sigma\n",
        "    #sig = np.repeat(np.repeat(np.repeat(\n",
        "    #    np.reshape(self.sigma, (-1, 1, 1)), self.periods+1, axis=2),\n",
        "    #    paths, axis=1), self.assets, axis=0)\n",
        "    \n",
        "    spot_paths[1:, :] = np.repeat(\n",
        "        spot_paths[0:1, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])"
      ],
      "metadata": {
        "id": "TshW4LLYDkEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_V = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':7, 'periods': 4, 'maturity': 3., 'strike' : 100,  'assets': 2,'spot':90,}\n",
        "S_test_U=Zvalues(**hyperparam_V)\n",
        "stock_paths_Z = S_test_U.simulate_process()\n",
        "print(stock_paths_Z)"
      ],
      "metadata": {
        "id": "ngTGSEUHZQk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_matrix = np.random.normal(0, 1, (S_test_U.periods+1, 3, 2))\n",
        "V_matrix = np.zeros((S_test_U.periods+1, 3, 2))\n",
        "V_matrix[0, :, :] = W_matrix[0, :, :]\n",
        "\n",
        "for i in range(1,S_test_U.periods+1):\n",
        "  V_matrix[i, :, :] = W_matrix[i, :, :] - W_matrix[i-1, :, :]\n",
        "print(V_matrix.shape) #(5, 3, 2)\n",
        "\n",
        "print(V_matrix)"
      ],
      "metadata": {
        "id": "qoquSY2VIlX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build z tilde matrix\n",
        "\n",
        "Z_matrix = np.zeros((S_test_U.periods+1, 3, 2))\n",
        "paths = S_test_U.paths\n",
        "dW = V_matrix * np.sqrt(S_test_U.dt)\n",
        "drift = S_test_U.drift\n",
        "r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), S_test_U.periods, axis=0),\n",
        "        paths, axis=1), 2, axis=2)\n",
        "sig = np.ones((S_test_U.periods, paths, 2))*S_test_U.sigma\n",
        "print(S_test_U.periods, stock_paths_Z.shape)\n",
        "a = np.repeat(stock_paths_Z[0:1, :], S_test_U.periods, axis=0)\n",
        "print(a.shape)\n",
        "print(stock_paths_Z[0:1, :])\n",
        "Z_matrix[1:, :, :] = np.repeat(stock_paths_Z[0:1, :], S_test_U.periods, axis=0)* np.exp(np.cumsum((r-S_test_U.delta) * S_test_U.dt - (sig ** 2) * S_test_U.dt / 2 + sig * dW, axis=0))"
      ],
      "metadata": {
        "id": "luS64oilSUXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate continuation values\n",
        "\n",
        "class continuation:\n",
        "  def __init__(self, model, payoff, mods):   \n",
        "    self.model = model # argument is S   \n",
        "    self.payoff = payoff(self.model)\n",
        "    self.mods = mods\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    stock_paths = self.model.simulate_process()\n",
        "\n",
        "    F_theta_test=np.zeros((model.periods+1,model.paths))\n",
        "    F_theta_test[model.periods,:]=1\n",
        "    C_test=np.zeros(self.model.periods+1)\n",
        "    \n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    C_test[model.periods] = np.mean(final_payoff)\n",
        "    payoff_0 = self.payoff.MaxCall(stock_paths[0, :, :])  \n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \":\", 1,\" , \", 1, \" , \", model.paths)\n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      mod_curr=self.mods[date]\n",
        "      probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "      np_probs=probs.detach().numpy().reshape(self.model.paths)\n",
        "      print(\"date\", date, \":\", round(np.min(np_probs), 3),\" , \", round(np.max(np_probs), 3), \" , \", len([1 for l in np_probs if l > 0.5]))\n",
        "\n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      values[which] = current_payoff[which]\n",
        "      values[~which] *= disc_factor\n",
        "      C_test[date]=np.mean(values)\n",
        "\n",
        "    \n",
        "    return C_test"
      ],
      "metadata": {
        "id": "bC6TxtJPXLwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continuation_values = continuation(S_test_U, Payoff, mods)\n",
        "\n",
        "print(continuation_values.price())"
      ],
      "metadata": {
        "id": "c5cbon3kXLzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = S\n",
        "payoff = Payoff(model)\n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "stock_paths = model.simulate_process()\n",
        "\n",
        "F_theta_test=np.zeros((model.periods+1,model.paths))\n",
        "F_theta_test[model.periods,:]=1\n",
        "C_test=np.zeros(model.periods+1)\n",
        "print(C_test)\n",
        "\n",
        "\n",
        "# at maturity N\n",
        "final_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "print(final_payoff)\n",
        "C_test[model.periods] = np.mean(final_payoff)"
      ],
      "metadata": {
        "id": "hJdetWn8i0__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stop(stock_values, current_payoff, future_payoff, train=True):\n",
        "    if train:\n",
        "      neural_stopping.train_network(\n",
        "          stock_values,\n",
        "          current_payoff ,\n",
        "          future_payoff)\n",
        "      inputs = stock_values\n",
        "      stopping_probability = neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability \n",
        "\n",
        "\n",
        "pricing = Recursive(S, Payoff, epochs=500)\n",
        "model = S\n",
        "payoff = Payoff(model)\n",
        "neural_stopping = Train_Network(model.assets, model.paths)\n",
        "\n",
        "stock_paths = model.simulate_process()    \n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    \n",
        "    \n",
        "    # AT MATURITY N\n",
        "final_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "payoff_0 = payoff.MaxCall(stock_paths[0, :, :])  \n",
        "values = final_payoff\n",
        "print(\"date\", model.periods, \":\", 1,\" , \", 1, \" , \", model.paths)\n",
        "\n",
        "\n",
        "# recursive calc, from n=N-1 to 0 with steps of -1\n",
        "\n",
        "date = 3   \n",
        "current_payoff = payoff.MaxCall(stock_paths[date, :, :])\n",
        "stopping_rule = stop(stock_paths[date, : , :], \n",
        "                          current_payoff,\n",
        "                          values*disc_factor)\n",
        "print(\"date\", date, \":\", round(np.min(stopping_rule), 3),\" , \", round(np.max(stopping_rule), 3), \" , \", len([1 for l in stopping_rule if l > 0.5]))\n",
        "which = stopping_rule > 0.5\n",
        "print(values)\n",
        "print(current_payoff)\n",
        "print(which)\n",
        "print(values[which])\n",
        "values[which] = current_payoff[which]\n",
        "values[~which] *= disc_factor"
      ],
      "metadata": {
        "id": "JVak1kL4v2JG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "optimal_stopping_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}