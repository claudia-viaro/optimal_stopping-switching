{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_stopping-switching/blob/main/optimal_stopping/optimal_stopping_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aX5-o2Sa7nC"
      },
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t^i = (b-\\delta_i)dt + \\sigma_i dW_t^i\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian otion on a filtered probability space $(\\Omega, \\mathcal{F}, (\\mathcal{F}_t)_{t \\geq 0}, \\mathbb{P})$ and $b$, $d_i$, $\\sigma_i >0$ are the drift. dividend yield and volatility of the system at time $t$.\n",
        "\n",
        "We will consider a discrete time approximization (Euler schema) on an equidistant time grid $0=t_0 < t_1 < \\ldots < t_N = T$, where $t_n = n \\cdot T/N$. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "x^p_{n,i} = x_{0,i} \\cdot \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\delta_i - \\sigma^2_i /2)\\Delta t + \\sigma_{i} \\sqrt{\\Delta t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\Delta t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "yEZA-EFaBd0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata\n",
        "from google.colab import files\n",
        "import helper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xJbxC0rzBhrT"
      },
      "outputs": [],
      "source": [
        "class BlackScholes:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths, self.assets ))\n",
        "\n",
        "    spot_paths[0, :, :] = self.spot\n",
        "    random_numbers = np.random.normal(\n",
        "        0, 1, (self.periods, paths, self.assets ))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1), self.assets, axis=2)\n",
        "    sig = np.ones((self.periods, paths, self.assets))*self.sigma\n",
        "    #sig = np.repeat(np.repeat(np.repeat(\n",
        "    #    np.reshape(self.sigma, (-1, 1, 1)), self.periods+1, axis=2),\n",
        "    #    paths, axis=1), self.assets, axis=0)\n",
        "    \n",
        "    spot_paths[1:, :,  :] = np.repeat(\n",
        "        spot_paths[0:1, :, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])\n",
        "\n",
        "\n",
        "\n",
        "class GBM:\n",
        "    def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike = 100,dividend=0):\n",
        "        self.maturity = maturity\n",
        "        self.strike = strike\n",
        "        self.assets = assets\n",
        "        self.sigma=sigma *np.ones(self.assets)\n",
        "        self.delta=delta\n",
        "        self.spot = spot*np.ones(self.assets)\n",
        "        self.drift = drift - dividend\n",
        "        self.paths = paths\n",
        "        self.periods = periods\n",
        "        self.dt = self.maturity / self.periods\n",
        "    \n",
        "    def simulate_process(self):\n",
        "        \n",
        "        dt = self.maturity / self.periods\n",
        "        So_vec=self.spot*np.ones((1,S.paths, S.assets))\n",
        "        \n",
        "        Z=np.random.standard_normal((self.periods,self.paths, self.assets))\n",
        "        s=self.spot*np.exp(np.cumsum((self.drift-self.delta-0.5*self.sigma**2)*dt+self.sigma*np.sqrt(dt)*Z, axis=0))\n",
        "        \n",
        "        s=np.append(So_vec, s, axis=0)\n",
        "        return s  \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MpTiRUxLBj5L"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Neural network\n",
        "'''\n",
        "\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = assets + 40\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.a1 = nn.Linear(assets, H)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.bn0(input)\n",
        "    out = self.a1(out)\n",
        "\n",
        "    out = self.relu(out)\n",
        "    #out = self.bn1(out)\n",
        "\n",
        "    #out = self.a2(out)\n",
        "    \n",
        "    #out = self.relu(out)\n",
        "    out = self.bn2(out)\n",
        "    out = self.a3(out)\n",
        "    \n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    # torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "FRYgMuM2C_K0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "PAYOFF\n",
        "'''\n",
        "\n",
        "# Payoff\n",
        "class Payoff:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "\n",
        "  def MaxCall(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def MaxPut(self, X):\n",
        "    payoff = self.strike - np.max(X, axis=1)\n",
        "    return payoff.clip(0, None)   \n",
        "\n",
        "\n",
        "  def GeometricPut(self, X):\n",
        "    dim = len(X[1])  \n",
        "    payoff = self.strike - np.prod(X, axis=1) ** (1/dim)\n",
        "    return payoff.clip(0, None)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class \"Recursive\"\n",
        "This class contains the main calculations of the algorithm, hence the recursion.\n",
        "\n",
        "### price\n",
        "First we start with some elements:\n",
        "1. we simulate $d$ asset prices $\\{X^i \\}^d_{i=1}$ along $m$ paths according to a geometric Brownian motion process. We consider the iys discretized version on an equidistant time grid, $t_n = n \\cdot T/N$ for $n=0, \\ldots, N$:\n",
        "\\begin{equation} \\tag{7}\n",
        "x_{n,i}^m = x_{0,i} \\cdot \\exp \\Big\\{\\sum_{k=0}^n \\Big((r-\\delta_i - \\sigma_i^2 /2) \\Delta t + \\sigma_i \\sqrt{\\Delta t} \\cdot Z_{k, i}^m  \\Big) \\Big\\}\n",
        "\\end{equation}\n",
        "where $(r-\\delta_i) \\in \\mathbb{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$, $\\Delta t =T/N$ and $Z_{k, i}^m \\sim \\mathcal{N}(0,1)$\n",
        "2. we define the discount factor $\\exp \\{(r-\\delta_i )\\Delta t \\}$\n",
        "\n",
        "\n",
        "Then we can start the recursion:\n",
        "\n",
        "*At maturity $N$*\n",
        "1. we compute the profit at $N$ \"final_payoff\" $(4)$\n",
        "\n",
        "*Before maturity, for each date $ n=N-1, \\ldots, 0$*\n",
        "1. we compute \"current_payoff\" using \"Profit_training.running()\"\n",
        "2. we obtain a stopping rule for each path, using as arguments the current payoff, the discounted final payoff (now called \"values\") and the entire process. Record then the stopping rules in \"F_theta_train\" **[I am not sure about the discounting]**\n",
        "3. we compute $\\check{V}_{n}^i$ according to $(4)$, using \"Payoff.Maxcall()\"  and record it under \"Y_train\". Hence we have a matrix with dimension periods x paths, recording $\\check{V}_{n}^i$\n",
        "5. we compute the mean estimate across paths for each date (Y_test_mean) and the standard error so that we can plot the values with a 95% CI"
      ],
      "metadata": {
        "id": "DkGCjRMDJuP6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "v1c9hUTGBzcz"
      },
      "outputs": [],
      "source": [
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Training_network(object):\n",
        "\n",
        "  def __init__(self, assets,  epochs=400, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "  # training part\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "        \n",
        "    # several optimization methods are available (here Adam algorithm). as argument input the parameters to be optimized    \n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    \n",
        "    # set values for the NN inputs (stock_values) and loss function\n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double() # input to the NN must be a tensor\n",
        "    self.network.train(True) # set training mode ON\n",
        "    ones = torch.ones(len(future_payoff)) # we need a vector of 1's in the loss function\n",
        "    losses = []\n",
        "    for epoch in range(self.epochs):\n",
        "      running_loss = 0.0\n",
        "\n",
        "      for batch in tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=self.batch_size, drop_last=False):\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "          F_theta = self.network.forward((X_inputs[batch])).reshape(-1) \n",
        "          reward = (current_payoff[batch].reshape(-1)* F_theta + \n",
        "                    future_payoff[batch] * (ones[batch] - F_theta)) \n",
        "          \n",
        "          # compute loss function\n",
        "          loss = -torch.mean(reward)\n",
        "          \n",
        "          # compute gradients\n",
        "          loss.backward()\n",
        "          # take a step, updating the parameters \n",
        "          optimizer.step()\n",
        "\n",
        "          running_loss += loss.item() * self.batch_size\n",
        "      epoch_loss = running_loss /  len(tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=self.batch_size, drop_last=False).sampler)\n",
        "      losses.append(epoch_loss)          \n",
        "    \n",
        "    torch.save(self.network.state_dict(), 'checkpoint.pth')\n",
        "\n",
        "    return F_theta, self.network, losses  \n",
        "  \n",
        "  # function to inform the NN to perform a testing phase\n",
        "  def evaluate_network(self, X_inputs):\n",
        "    state_dict = torch.load('checkpoint.pth')\n",
        "    self.network.load_state_dict(state_dict)\n",
        "\n",
        "    self.network.eval()\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    \n",
        "    # the output is a probability for each date and path\n",
        "    # it is obtained by feeding the NN with the dimension of the assets (at a specific date for all paths), \n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()).detach().numpy()\n"
      ],
      "metadata": {
        "id": "ZbIYQqM3bKnb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training\n",
        "\n",
        "We conduct $3000+d$ training steps and for each we generate a batch of $8192$ paths of $(X_n)_{n=0}^N$.\n",
        "\n",
        "The resulting output will be the stopping decisions $f^{\\theta_n}$\n"
      ],
      "metadata": {
        "id": "F67WgZCjmvmS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate paths Y\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':20, 'periods': 9, 'maturity': 1., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_train=BlackScholes(**hyperparam_training)\n"
      ],
      "metadata": {
        "id": "67CEvqrDYbYI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "  def __init__(self, model, payoff_function):\n",
        "\n",
        "    self.model = model\n",
        "    self.payoff = payoff_function(self.model)\n",
        "    self.neural_stopping = Training_network(self.model.assets)\n",
        "\n",
        "  def value(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    mods=[None]*model.periods # record the models of the NN for testing\n",
        "    loss_functions = [None]*model.periods\n",
        "    \n",
        "    \n",
        "    # AT MATURITY N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    print(\"date\", model.periods, \",\", model.paths)\n",
        " \n",
        "\n",
        "    # from n=N-1 to 0 with steps of -1\n",
        "\n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):      \n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      stopping_rule , networks, loss = self.neural_stopping.train_network(stock_paths[date, : , :], \n",
        "                                                  current_payoff,\n",
        "                                                  final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "      mods[date]=networks\n",
        "      loss_functions[date]=loss\n",
        "      print(\"date\", date, \",\", len([1 for l in stopping_rule if l > 0.5]), \" mean loss \", np.mean(loss))\n",
        "\n",
        "\n",
        "    return mods, loss_functions\n",
        "\n",
        "  def stop(self, stock_values, current_payoff, future_payoff, train=True):\n",
        "    if train:\n",
        "      stopping_probability, networks, losses = self.neural_stopping.train_network(stock_values,\n",
        "                                                                          current_payoff,\n",
        "                                                                          future_payoff)\n",
        "      #inputs = stock_values\n",
        "      #stopping_probability , networks   = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability, networks, losses  "
      ],
      "metadata": {
        "id": "T6mxhgqPaQj5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pricing = Training(S_train, Payoff)\n",
        "mods, loss_function = pricing.value()"
      ],
      "metadata": {
        "id": "2XEhZY0obdbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a2e624-f2f9-477a-8473-fa50e24784cf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 9 , 20\n",
            "date 8 , 5  mean loss  -331.46735663428376\n",
            "date 7 , 2  mean loss  -329.26859268781226\n",
            "date 6 , 1  mean loss  -323.6880400167691\n",
            "date 5 , 2  mean loss  -316.8774580118984\n",
            "date 4 , 0  mean loss  -311.1428225124987\n",
            "date 3 , 0  mean loss  -304.5723559810087\n",
            "date 2 , 0  mean loss  -297.8787755140147\n",
            "date 1 , 0  mean loss  -291.33225397192473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = list(filter(None, loss_function))\n",
        "legend = [\"n = 1\", \"n = 2\", \"n = 3\", \"n = 4\", \"n = 5\", \"n = 6\", \"n = 7\", \"n = 8\"]\n",
        "\n",
        "for i in range(len(filtered_list)):\n",
        "  epochs = np.array([i for i in range(len(filtered_list[0]))])\n",
        "  plt.plot(epochs, filtered_list[i], label='loss funciton')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend(legend)\n",
        "  plt.title('Loss curves across time periods')\n",
        "  plt.plot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "6IewJAQSf8OT",
        "outputId": "828d4922-d81a-4a32-e287-4d790c9f1d32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "# CHECK TRAINING\n",
        "\n",
        "# check training\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':7, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "model=BlackScholes(**hyperparam_training)\n",
        "payoff = Payoff(model)\n",
        "stock_paths = model.simulate_process()    \n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "mods=[None]*model.periods\n",
        "    \n",
        "    \n",
        "# AT MATURITY N\n",
        "immediate_exercise_value = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "final = immediate_exercise_value\n",
        "\n",
        "\n",
        "# recursive calc. before maturity\n",
        "date = stock_paths.shape[0] - 3\n",
        "print(\"date\", date)\n",
        "immediate_exercise_value =  payoff.MaxCall(stock_paths[date, :, :])\n",
        "immediate_exercise_value = torch.from_numpy(immediate_exercise_value).double()\n",
        "discounted_next_values = disc_factor * (torch.from_numpy(final).double())\n",
        "X_inputs = torch.from_numpy(stock_paths[date, : , :]).double() # input to the NN must be a tensor\n",
        "\n",
        "print(X_inputs.shape) # 7 paths, 2 assets for that date\n",
        "print(\"X_inputs\", X_inputs)\n",
        "\n",
        "\n",
        "\n",
        "for batch in tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=4, drop_last=False):\n",
        "  print(\"batch\", X_inputs[batch])\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "5oB2_W0Yi5p6",
        "outputId": "56660ebe-32fc-4198-8bff-9f53714aa805"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# CHECK TRAINING\\n\\n# check training\\nhyperparam_training = {\\'drift\\': 0.2, \\'sigma\\': 0.05, \\'delta\\': 0.1,  \\'paths\\':7, \\'periods\\': 9, \\'maturity\\': 3., \\'strike\\' : 100,\\'assets\\':2,  \\'spot\\':90,}\\nmodel=BlackScholes(**hyperparam_training)\\npayoff = Payoff(model)\\nstock_paths = model.simulate_process()    \\ndisc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\\nmods=[None]*model.periods\\n    \\n    \\n# AT MATURITY N\\nimmediate_exercise_value = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\\nfinal = immediate_exercise_value\\n\\n\\n# recursive calc. before maturity\\ndate = stock_paths.shape[0] - 3\\nprint(\"date\", date)\\nimmediate_exercise_value =  payoff.MaxCall(stock_paths[date, :, :])\\nimmediate_exercise_value = torch.from_numpy(immediate_exercise_value).double()\\ndiscounted_next_values = disc_factor * (torch.from_numpy(final).double())\\nX_inputs = torch.from_numpy(stock_paths[date, : , :]).double() # input to the NN must be a tensor\\n\\nprint(X_inputs.shape) # 7 paths, 2 assets for that date\\nprint(\"X_inputs\", X_inputs)\\n\\n\\n\\nfor batch in tdata.BatchSampler(\\n              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\\n              batch_size=4, drop_last=False):\\n  print(\"batch\", X_inputs[batch])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lower bound\n",
        "\n",
        "the stopping time $\\tau^{\\Theta}$ gives a lower bound $L=\\mathbb{E}g(\\tau^{\\Theta}, X_{\\tau^{\\Theta}})$ for the optimal value $V_0= \\sup_{\\tau \\in \\mathcal{T}}\\mathbb{E}g(\\tau, X_{\\tau})$.\n",
        "\n",
        "Simulate \n",
        "- $K_L = 1024$ paths $(y_n^k)_{n=0}^N$, $k=1, \\ldots, K_L$, of $(X_n)_{n=0}^N$ and assume these are drawn independently from the realizations $(x_n^k)_{n=0}^N$, $k=1, \\ldots, K$.\n",
        "\n",
        "The unbiased estimate of the lower bound $L$ is given by\n",
        "\\begin{equation}\n",
        "\\hat{L}=\\frac{1}{K_L} \\sum_{k=1}^{K_L} g(l^k, y_{l^k}^k)\n",
        "\\end{equation}\n",
        "where $l^k = l(y_0^k, \\ldots, y_{N-1}^k)$"
      ],
      "metadata": {
        "id": "u6ULiVMClRqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Lower bound\n",
        "\n",
        "# sample y from the process (Y)\n",
        "hyperparam_testing_L = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':40, 'periods': 9, 'maturity': 1., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_test_L=BlackScholes(**hyperparam_testing_L)\n",
        "\n",
        "# now we can compute all the stopping times recursively"
      ],
      "metadata": {
        "id": "fFwBlDkLbnxg"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "model = S_test_L\n",
        "stock_paths = model.simulate_process()\n",
        "date = stock_paths.shape[0] - 2\n",
        "\n",
        "mod_curr = mods[date]     \n",
        "probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "np_probs=probs.detach().numpy().reshape(model.paths)     \n",
        "which = np_probs > 0.5\n",
        "print(which)\n",
        "\n",
        "neural_stopping = Training_network(model.assets, model.paths)\n",
        "stopping_probability , networks   = neural_stopping.evaluate_network(stock_paths[date])\n",
        "print(stopping_probability  > 0.5)\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "MW7B4vELqcXd",
        "outputId": "4ecdc302-dc56-43e6-da8e-78e15015a6d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nmodel = S_test_L\\nstock_paths = model.simulate_process()\\ndate = stock_paths.shape[0] - 2\\n\\nmod_curr = mods[date]     \\nprobs=mod_curr(torch.from_numpy(stock_paths[date])) \\nnp_probs=probs.detach().numpy().reshape(model.paths)     \\nwhich = np_probs > 0.5\\nprint(which)\\n\\nneural_stopping = Training_network(model.assets, model.paths)\\nstopping_probability , networks   = neural_stopping.evaluate_network(stock_paths[date])\\nprint(stopping_probability  > 0.5)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "class Testing_Lower:\n",
        "  def __init__(self, model, payoff, mods):   \n",
        "    self.model = model # argument is S   \n",
        "    self.payoff = payoff(self.model)\n",
        "    #self.neural_stopping = Training_network(self.model.assets)\n",
        "    self.mods = mods\n",
        "\n",
        "\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model    \n",
        "    stock_paths = self.model.simulate_process()\n",
        "    \n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    payoff_0 = self.payoff.MaxCall(stock_paths[0, :, :])  \n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \":\", 1.0,\" , \", 1.0, \" , \", model.paths, \"value\", round(np.mean(values), 3))\n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      mod_curr=self.mods[date]\n",
        "\n",
        "      #probs = self.neural_stopping.evaluate_network(stock_paths[date, : , :])\n",
        "      \n",
        "      probs=mod_curr(torch.from_numpy(stock_paths[date, :, :])) \n",
        "      np_probs=probs.detach().numpy().reshape(self.model.paths)     \n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      values[which] = current_payoff[which]\n",
        "      values[~which] *= (np.math.exp((-model.drift) * (model.periods-date)/model.periods))\n",
        "      print(\"date\", date, \":\", round(np.min(np_probs), 3),\" , \", round(np.max(np_probs), 3), \" , \", len([1 for l in np_probs if l > 0.5]), \"value\", round(np.mean(values), 3))\n",
        "\n",
        "    \n",
        "    return round(payoff_0[0], 3), round(np.mean(values)*(np.math.exp((-model.drift) * (date/model.periods))) , 3)\n",
        "\n"
      ],
      "metadata": {
        "id": "aNegNcskb5gl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_testing = Testing_Lower(S_test_L, Payoff, mods)\n",
        "\n",
        "Y_test_mean, MC_estimate = price_testing.price()\n",
        "print(Y_test_mean, MC_estimate)"
      ],
      "metadata": {
        "id": "1oRLovDLcEwE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e7f745-5e2c-4f00-ae0d-29442ed2486d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 9 : 1.0  ,  1.0  ,  40 value 2.964\n",
            "date 8 : 0.0  ,  0.0  ,  0 value 2.899\n",
            "date 7 : 0.0  ,  0.0  ,  0 value 2.773\n",
            "date 6 : 0.0  ,  0.0  ,  0 value 2.594\n",
            "date 5 : 0.0  ,  0.0  ,  0 value 2.373\n",
            "date 4 : 0.0  ,  0.0  ,  0 value 2.124\n",
            "date 3 : 0.0  ,  0.0  ,  0 value 1.859\n",
            "date 2 : 0.0  ,  0.0  ,  0 value 1.591\n",
            "date 1 : 0.0  ,  0.0  ,  0 value 1.332\n",
            "0.0 1.302\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upper Bound\n",
        "\n",
        "For every $(\\mathcal{F}_n)$-martingale $(M_n)_{n=0}^N$ starting from $0$ and each sequence of integrable error terms $(\\epsilon_n)_{m=0}^N$ satisfying $\\mathbb{E}[\\epsilon_n | \\mathcal{F}_n]=0$ for all $n$, the following expression provides an upper bound for $V_0$, which is also tight if $M=M^H$ and $\\epsilon \\equiv 0$.\n",
        "\\begin{equation}\n",
        "U = \\mathbb{E} \\Big[ \\max_{0 \\leq n \\leq N} [g(n, X_n) - M_n^{\\Theta} - \\epsilon_n ]  \\Big]\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "We need an expression for $M^H$ and use the Doob-Meyer decomposition on the Snell envelope of the reward process:\n",
        "\\begin{equation}\n",
        "H_n = \\text{ess} \\sup_{\\tau \\in \\mathcal{T}_n} \\mathbb{E}[g(\\tau)| \\mathcal{F}_n], \\;\\;\\;\\ n=0, 1, \\ldots, N\n",
        "\\end{equation}\n",
        "where its Doob-Meyer deomposition is given by:\n",
        "\\begin{equation}\n",
        "H_n = H_0 + M_n^H - A_n^H\n",
        "\\end{equation}\n",
        "and\n",
        "\\begin{equation}\n",
        "M_0^H = 0\\;\\;\\;\\; \\text{and} \\;\\; M_n^H-M_{n-1}^H=H_n-\\mathbb{E}[H_n | \\mathcal{F}_{n-1}], \\;\\;\\; n=1, \\ldots, N\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "\n",
        "We use $\\tau^{\\Theta}$ to construct a martingale close to $M^H$. The martingale part of $(H_n^{\\Theta})_{n=0}^N$ is given by:\n",
        "\\begin{equation}\n",
        "\\begin{split}\n",
        "&M_0^{\\Theta}\\\\\n",
        "&M_N^{\\Theta}- M_{n-1}^{\\Theta} = H_n^{\\Theta}-\\mathbb{E}[H_n^{\\Theta} | \\mathcal{F}_{n-1}] = f^{\\theta_n}(X_n)g(n, X_n) + (1- f^{\\theta_n})) C_n^{\\Theta}-C_{n-1}^{\\Theta}, \\;\\; n \\geq 1\n",
        "\\end{split}\n",
        "\\end{equation}\n",
        "and the continuation value is:\n",
        "\\begin{equation}\n",
        "C_n^{\\Theta}=\\mathbb{E}[g(\\tau_{n+1}^{\\Theta}, X_{\\tau_{n+1}^{\\Theta}})| \\mathcal{F}_n] = \\mathbb{E}[g(\\tau_{n+1}^{\\Theta}, X_{\\tau_{n+1}^{\\Theta}})| X_n], \\;\\;\\;\\ n=0, 1, \\ldots, N-1\n",
        "\\end{equation}\n",
        "there is no need to specify $C_N^{\\Theta}$ because $(1- f^{\\theta_N}(X_N))$ is always $0$.\n",
        "\n",
        "\n",
        "Simulate \n",
        "- $K_U = 1024$ paths $(z_n^k)_{n=0}^N$, $k=1, \\ldots, K_U$, of $(X_n)_{n=0}^N$\n",
        "- $K_U \\times J$ realizations $(v_n^{k,j})_{n=0}^N$, $k=1, \\ldots, K_U$, $j=1, \\ldots, J$, of $(W_{t_n} - W_{t_n - 1})_{n=1}^N$ with $J=16384$\n",
        "- for all $n$ and $k$, generate the $i$-th component of the $j$-th continuation path departing from  $z_n^k$ according to:\n",
        "\\begin{equation}\n",
        "\\tilde{z}_n^{i,k,j}=z_n^{i,k} \\exp \\Big([r- \\delta_i - \\sigma_i^2 /2] (m-n)\\Delta t + \\sigma_i [v_{n+1}^{i,k,j} + \\ldots, v_{m}^{i,k,j}]  \\Big), \\;\\;\\;\\; m=n+1, \\ldots, N\n",
        "\\end{equation}\n",
        "we assume that $\\tilde{z}_{n+1}^{k,j}, \\ldots, \\tilde{z}_{N}^{k,j}$ are conditionally independent of each other and of $z_{n+1}^{k}, \\ldots, z_{N}^{k}$ \n"
      ],
      "metadata": {
        "id": "ffDydd-UaBXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Upper bound\n",
        "\n",
        "# sample Z from the process (X)\n",
        "hyperparam_testing_U = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':1024, 'periods': 4, 'maturity': 3., 'strike' : 100,'assets':1,  'spot':90,}\n",
        "S_test_U=BlackScholes(**hyperparam_testing_U)\n",
        "stock_paths = S_test_U.simulate_process()\n",
        "print(stock_paths.shape) #(5, 1024, 1)"
      ],
      "metadata": {
        "id": "vSpdEj0XXLuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need to generate v values\n",
        "\n",
        "class Zvalues:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths))\n",
        "\n",
        "    spot_paths[0, :] = self.spot\n",
        "    random_numbers = np.random.normal(\n",
        "        0, 1, (self.periods, paths))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1)\n",
        "    sig = np.ones((self.periods, paths))*self.sigma\n",
        "    #sig = np.repeat(np.repeat(np.repeat(\n",
        "    #    np.reshape(self.sigma, (-1, 1, 1)), self.periods+1, axis=2),\n",
        "    #    paths, axis=1), self.assets, axis=0)\n",
        "    \n",
        "    spot_paths[1:, :] = np.repeat(\n",
        "        spot_paths[0:1, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])"
      ],
      "metadata": {
        "id": "TshW4LLYDkEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_V = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':7, 'periods': 4, 'maturity': 3., 'strike' : 100,  'assets': 2,'spot':90,}\n",
        "S_test_U=Zvalues(**hyperparam_V)\n",
        "stock_paths_Z = S_test_U.simulate_process()\n",
        "print(stock_paths_Z)"
      ],
      "metadata": {
        "id": "ngTGSEUHZQk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_matrix = np.random.normal(0, 1, (S_test_U.periods+1, 3, 2))\n",
        "V_matrix = np.zeros((S_test_U.periods+1, 3, 2))\n",
        "V_matrix[0, :, :] = W_matrix[0, :, :]\n",
        "\n",
        "for i in range(1,S_test_U.periods+1):\n",
        "  V_matrix[i, :, :] = W_matrix[i, :, :] - W_matrix[i-1, :, :]\n",
        "print(V_matrix.shape) #(5, 3, 2)\n",
        "\n",
        "print(V_matrix)"
      ],
      "metadata": {
        "id": "qoquSY2VIlX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build z tilde matrix\n",
        "\n",
        "Z_matrix = np.zeros((S_test_U.periods+1, 3, 2))\n",
        "paths = S_test_U.paths\n",
        "dW = V_matrix * np.sqrt(S_test_U.dt)\n",
        "drift = S_test_U.drift\n",
        "r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), S_test_U.periods, axis=0),\n",
        "        paths, axis=1), 2, axis=2)\n",
        "sig = np.ones((S_test_U.periods, paths, 2))*S_test_U.sigma\n",
        "print(S_test_U.periods, stock_paths_Z.shape)\n",
        "a = np.repeat(stock_paths_Z[0:1, :], S_test_U.periods, axis=0)\n",
        "print(a.shape)\n",
        "print(stock_paths_Z[0:1, :])\n",
        "Z_matrix[1:, :, :] = np.repeat(stock_paths_Z[0:1, :], S_test_U.periods, axis=0)* np.exp(np.cumsum((r-S_test_U.delta) * S_test_U.dt - (sig ** 2) * S_test_U.dt / 2 + sig * dW, axis=0))"
      ],
      "metadata": {
        "id": "luS64oilSUXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Estimate continuation values\n",
        "\n",
        "class continuation:\n",
        "  def __init__(self, model, payoff, mods):   \n",
        "    self.model = model # argument is S   \n",
        "    self.payoff = payoff(self.model)\n",
        "    self.mods = mods\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    stock_paths = self.model.simulate_process()\n",
        "\n",
        "    F_theta_test=np.zeros((model.periods+1,model.paths))\n",
        "    F_theta_test[model.periods,:]=1\n",
        "    C_test=np.zeros(self.model.periods+1)\n",
        "    \n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    C_test[model.periods] = np.mean(final_payoff)\n",
        "    payoff_0 = self.payoff.MaxCall(stock_paths[0, :, :])  \n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \":\", 1,\" , \", 1, \" , \", model.paths)\n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.payoff.MaxCall(stock_paths[date, :, :])\n",
        "      mod_curr=self.mods[date]\n",
        "      probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "      np_probs=probs.detach().numpy().reshape(self.model.paths)\n",
        "      print(\"date\", date, \":\", round(np.min(np_probs), 3),\" , \", round(np.max(np_probs), 3), \" , \", len([1 for l in np_probs if l > 0.5]))\n",
        "\n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      values[which] = current_payoff[which]\n",
        "      values[~which] *= disc_factor\n",
        "      C_test[date]=np.mean(values)\n",
        "\n",
        "    \n",
        "    return C_test"
      ],
      "metadata": {
        "id": "bC6TxtJPXLwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continuation_values = continuation(S_test_U, Payoff, mods)\n",
        "\n",
        "print(continuation_values.price())"
      ],
      "metadata": {
        "id": "c5cbon3kXLzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = S\n",
        "payoff = Payoff(model)\n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "stock_paths = model.simulate_process()\n",
        "\n",
        "F_theta_test=np.zeros((model.periods+1,model.paths))\n",
        "F_theta_test[model.periods,:]=1\n",
        "C_test=np.zeros(model.periods+1)\n",
        "print(C_test)\n",
        "\n",
        "\n",
        "# at maturity N\n",
        "final_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "print(final_payoff)\n",
        "C_test[model.periods] = np.mean(final_payoff)"
      ],
      "metadata": {
        "id": "hJdetWn8i0__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stop(stock_values, current_payoff, future_payoff, train=True):\n",
        "    if train:\n",
        "      neural_stopping.train_network(\n",
        "          stock_values,\n",
        "          current_payoff ,\n",
        "          future_payoff)\n",
        "      inputs = stock_values\n",
        "      stopping_probability = neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability \n",
        "\n",
        "\n",
        "pricing = Recursive(S, Payoff, epochs=500)\n",
        "model = S\n",
        "payoff = Payoff(model)\n",
        "neural_stopping = Train_Network(model.assets, model.paths)\n",
        "\n",
        "stock_paths = model.simulate_process()    \n",
        "disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    \n",
        "    \n",
        "    # AT MATURITY N\n",
        "final_payoff = payoff.MaxCall(stock_paths[-1, :, :]) # payoff of the last date\n",
        "payoff_0 = payoff.MaxCall(stock_paths[0, :, :])  \n",
        "values = final_payoff\n",
        "print(\"date\", model.periods, \":\", 1,\" , \", 1, \" , \", model.paths)\n",
        "\n",
        "\n",
        "# recursive calc, from n=N-1 to 0 with steps of -1\n",
        "\n",
        "date = 3   \n",
        "current_payoff = payoff.MaxCall(stock_paths[date, :, :])\n",
        "stopping_rule = stop(stock_paths[date, : , :], \n",
        "                          current_payoff,\n",
        "                          values*disc_factor)\n",
        "print(\"date\", date, \":\", round(np.min(stopping_rule), 3),\" , \", round(np.max(stopping_rule), 3), \" , \", len([1 for l in stopping_rule if l > 0.5]))\n",
        "which = stopping_rule > 0.5\n",
        "print(values)\n",
        "print(current_payoff)\n",
        "print(which)\n",
        "print(values[which])\n",
        "values[which] = current_payoff[which]\n",
        "values[~which] *= disc_factor"
      ],
      "metadata": {
        "id": "JVak1kL4v2JG"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "optimal_stopping_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}