{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_switching/blob/main/optimal_stopping_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aX5-o2Sa7nC"
      },
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, P)$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t = b_{I_t}X_tdt + \\sigma_{I_t}X_tdW_t\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian otion on a filtered probability space $(\\Omega, \\mathcal{F}, \\mathbf{F}=(\\mathcal{F}_t)_{t \\geq 0} P)$ and $I_t$ is the indicator variable of the regimes valued in $\\mathbf{I}_d = \\{1, \\ldots, d \\}$. $b_i \\in \\mathbf{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$ once in regime $I_t=i$ at time $t$.\n",
        "\n",
        "We will consider a discrete approximization (Euler schema) with respect to. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "X^p_{n,i} = \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\sigma^2_i /2)_{\\mathbf{I}}\\Delta t + \\sigma_{i, \\mathbf{I}} \\sqrt{\\Delta t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\Delta t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "yEZA-EFaBd0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "xJbxC0rzBhrT"
      },
      "outputs": [],
      "source": [
        "''' \n",
        "underlying process - Geometric brownian motion\n",
        "'''\n",
        "\n",
        "class GBM:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-drift * self.dt)\n",
        "    self.strike = strike\n",
        "\n",
        "  def simulate_process(self):\n",
        "    paths = self.paths\n",
        "    path = np.array([self.simulate_one_path() for i in range(paths)]) \n",
        "    return path.reshape(path.shape[2], path.shape[0], path.shape[1])\n",
        "\n",
        "  def drift_fct(self,x):\n",
        "    return  (self.drift-self.delta-0.5*self.sigma**2)* x\n",
        "\n",
        "  def diffusion_fct(self,x):\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "  def simulate_one_path(self):\n",
        "    path = np.empty((self.assets, self.periods+1))\n",
        "    path[:, 0] = self.spot\n",
        "    for k in range(1, self.periods+1):\n",
        "      random_numbers = np.random.normal(0, 1, self.assets)\n",
        "      dW =(random_numbers*np.sqrt(self.dt))\n",
        "      previous_spots = path[:, k - 1]\n",
        "      diffusion = (self.diffusion_fct(previous_spots))\n",
        "      path[:, k] = (\n",
        "          previous_spots\n",
        "          + self.drift_fct(previous_spots)* self.dt\n",
        "          + diffusion*dW) \n",
        "    return path   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqmbYE_8z_fe"
      },
      "source": [
        "As introduced, the stochastic system can operate in $m$ modes or regimes from the finite set $\\mathbb{I}=\\{1, \\ldots , m \\}$. In this case we consider $m=2$ with $\\mathbb{I}=\\{\\text{on}, \\text{off} \\}$. \n",
        "\n",
        "The regimes can be switched at a sequence of stopping times over a finite horizon $[0, \\ldots , T]$.\n",
        "\n",
        "There is a payoff rate per unit of time when the system is in mode $i \\in \\mathbb{I}$ at time $t$ as a mapping $\\Psi_i(t, X_t): \\Omega \\times [0, T] \\rightarrow \\mathbb{R}$. The payoff function for the call option used is of the form $( \\max_{i \\in \\{ 1, \\ldots , d \\}} X_t^i - K) ^{+}$, where $K$ is the strike price at any point in the time grid $0 = t_0 < t_1 < \\ldots < t_N = T$. the system also outputs a final reward for being in mode $i \\in \\mathbb{I}$ at time $T$ given by $\\Gamma_i$.\n",
        "\n",
        "There is a cost for switching from regime $i$ to $j$ given by the function $\\gamma_{i, j} : \\Omega \\times [0, T] \\rightarrow \\mathbb{R} $ to cover for the extra costs due to the change of the regime.\n",
        "\n",
        "A strategy $\\alpha$ for the power plant will be a combination of two sequences:\n",
        "- non decreasing sequence of $\\mathbb{F}$-stopping times $(\\tau_n)_{n \\geq 1}$, $n \\in \\mathbb{N} \\backslash \\{0\\}$, where at $\\tau_n$ the production is swithced from the current mode $i$ to $j$. we also assume: $\\tau_0=t$ and $\\tau_n \\leq \\tau_{n+1}$.\n",
        "- a sequence of indicators $(\\iota)_{n \\geq 1}$, $n \\in \\mathbb{N} \\backslash \\{0\\}$, $\\mathcal{F}_{\\tau_n}$- measurable valued in $\\mathbb{I}_m$. At time $t=\\tau_n$ the system is switched from the current regime $\\iota_{n-1}$ to $\\iota_{n}$, with $\\iota_{0}=i$.\n",
        "\n",
        "We denote by $\\mathcal{A}_{t, i}$ the set of admissible strategies to switch at time $\\tau_n$, $n \\geq 1$, from the current regime $\\iota_{n-1}$ to $\\iota_{n}$. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KsWsO53nz_lG"
      },
      "source": [
        "For any initial condition $(x, i) \\in [0, T] \\times \\mathbb{I}_m$, and any control $\\alpha=(\\tau_n, \\iota_n)_{n \\leq 0} \\in \\mathcal{A}_{t, i}$. the total expected payoff up to $T$ for such strategy can be expressed as: \n",
        "\\begin{equation}\n",
        "J_i(x, \\alpha) = \\mathbb{E} \\Big[ \\sum_{s=t}^{T-1} \\Psi(X_t^{x, i}, I_t^i) + \\Gamma - \\sum_{n \\leq 1}\\gamma_{\\iota_{n-1}, \\iota_n} \\mathbf{1}_{ \\{ \\tau_n < T \\} }  | \\mathcal{F}_n   \\Big]\n",
        "\\end{equation}\n",
        "\n",
        "The objective is to maximize this expected total profit for all strategies $\\alpha$. For this purpose, we set the value function:\n",
        "\\begin{equation}\n",
        "V_i(x)=\\sup_{\\alpha \\in \\mathcal{A}} J_i(x, \\alpha) \\;\\;\\;\\;\\;\\;\\;\\;\\; \\forall \\alpha \\in \\mathcal{A}_{t, i} \\,\\, \\mathbb{P}\\; a.s. \n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTuPqVNSVB-i"
      },
      "source": [
        "Following Becker, Cheridito and Jentzen, we reformulate stopping time problem into a sequence of $0-1$ stopping decisions. To optimally stop the Markov process $X$ we make stopping decisions according to $f_n(X_n)$ for measurable functions $f_n: \\mathbb{R}^d â†’ \\{0, 1 \\}, n \\in \\mathbb{N}$. By construction $f_N \\equiv 1$ as at $n=N$ there is a terminal stopping decision where $\\tau_N \\equiv N$. \n",
        "\n",
        "Given $n \\in \\{0, 1, \\ldots, N-1 \\}$ and the final stopping decision, let $\\tau_{n+1}$ be a stopping time in $\\mathcal{T}_{n+1}$ of the form:\n",
        "\\begin{equation}\n",
        "\\tau_{n+1} = \\sum_{m=n+1}^N m f_m(X_m) \\prod _{j=n+1}^{m-1} (1-f_j(X_j))\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "To approach the problem, we iteratively approximate the optimal stopping decisions $f_n: \\mathbb{R}^d \\rightarrow \\{0, 1 \\}, n = \\{ 1, 2, \\ldots, N-1 \\}$, by a neural network $f^{\\theta}: \\mathbb{R}^d \\rightarrow \\{0, 1 \\}$ with parameter $\\theta \\in \\mathbb{R}^q$. We choose $\\theta_N \\in \\mathbb{R}^q$ such that $f^{\\theta}_N \\equiv 1$ and determine $\\theta_n \\in \\mathbb{R}^q$ for $n \\leq N-1$ by recursion of the form:\n",
        "\n",
        "\\begin{equation}\n",
        "\\tau_{n+1} = \\sum_{m=n+1}^N m f^{\\theta_m}(X_m) \\prod _{j=n+1}^{m-1} (1-f^{\\theta_j}(X_j))\n",
        "\\end{equation}\n",
        "\n",
        "Since $f^{\\theta}$ takes values in $\\{ 0,1 \\}$, hence not appropriate for a gradient-descent optimization method, the neural network includes a layer performing a logostic transformation such that we have the resulting output function $F^{\\theta}: \\mathbb{R}^d \\rightarrow (0,1)$.\n",
        "\n",
        "The Neural network includes $(d+40)$ hidden units and comprises a combination of linear and rectified linear activation functions. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "MpTiRUxLBj5L"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Neural network\n",
        "'''\n",
        "\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets, hidden_size):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = hidden_size\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.layer1 = nn.Linear(assets, H)\n",
        "    self.leakyReLU = nn.LeakyReLU(0.5)\n",
        "    self.Softplus = nn.Softplus()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.layer2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.layer3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn0(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    # torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n",
        "    \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "ARr530-tBreb"
      },
      "outputs": [],
      "source": [
        "class Train_Network(object):\n",
        "\n",
        "  def __init__(self, assets, paths, epochs=20, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets, hidden_size=self.assets+40).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "        \n",
        "    # several optimization methods are available (here Adam algorithm). as argument input the parameters to be optimized    \n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    \n",
        "    # set values for the NN inputs (stock_values) and loss function\n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double() # input to the NN must be a tensor\n",
        "\n",
        "    self.network.train(True) # set training mode ON\n",
        "    ones = torch.ones(len(future_payoff)) # we need a vector of 1's in the loss function\n",
        "    for epoch in range(self.epochs):\n",
        "      # set the gradients of all optimized tensors to zero (at every step we start fresh)\n",
        "      optimizer.zero_grad()\n",
        "      F_theta = self.network(X_inputs).reshape(-1) # probabilities\n",
        "      reward = (current_payoff.reshape(-1)[0] * F_theta + future_payoff * (ones - F_theta)) \n",
        "      \n",
        "      # compute loss function\n",
        "      loss = -torch.mean(reward)\n",
        "      \n",
        "      # compute gradients\n",
        "      loss.backward()\n",
        "      \n",
        "      # take a step, updating the parameters \n",
        "      optimizer.step()\n",
        "  \n",
        "  # function to inform the NN to perform a training\n",
        "  def evaluate_network(self, X_inputs):\n",
        "    self.network.train(False)\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    \n",
        "    # the output is a probability for each date and path\n",
        "    # it is obtained by feeding the NN with the dimension of the assets (at a specific date for all paths), \n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()[0]).detach().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "FRYgMuM2C_K0"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "PAYOFF\n",
        "'''\n",
        "\n",
        "# Payoff\n",
        "class Payoff:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "\n",
        "  def MaxCall(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def MaxPut(self, X):\n",
        "    payoff = self.strike - np.max(X, axis=1)\n",
        "    return payoff.clip(0, None)   \n",
        "\n",
        "\n",
        "  def GeometricPut(self, X):\n",
        "    dim = len(X[1])  \n",
        "    payoff = self.strike - np.prod(X, axis=1) ** (1/dim)\n",
        "    return payoff.clip(0, None)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "yQtkD5yJCx75"
      },
      "outputs": [],
      "source": [
        "class Recursive:\n",
        "  def __init__(self, model, payoff_function, epochs=20):\n",
        "\n",
        "    self.model = model\n",
        "    self.payoff = payoff_function(self.model)\n",
        "    self.neural_stopping = Train_Network(model.assets, model.paths)\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    \n",
        "    # AT MATURITY N\n",
        "    final_payoff = self.payoff.MaxPut(stock_paths[-1, :, :]) # payoff of the last date\n",
        "    payoff_0 = self.payoff.MaxPut(stock_paths[0, :, :])  \n",
        "    values = final_payoff\n",
        "\n",
        "\n",
        "    # recursive calc, from n=N-1 to 0 with steps of -1\n",
        "\n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.payoff.MaxPut(stock_paths[date, :, :])\n",
        "      stopping_rule = self.stop(stock_paths[date, : , :], \n",
        "                                current_payoff,\n",
        "                                values*disc_factor)\n",
        "      print(date, \":\", np.min(stopping_rule),\" , \", np.max(stopping_rule), \" , \", len([1 for l in stopping_rule if l > 0.5]))\n",
        "      which = stopping_rule > 0.5\n",
        "\n",
        "      values[which] = current_payoff[which]\n",
        "      values[~which] *= disc_factor\n",
        "\n",
        "\n",
        "    return print(max(payoff_0[0] , np.mean(values)* disc_factor))\n",
        "\n",
        "  def stop(self, stock_values, current_payoff, future_payoff):\n",
        "    self.neural_stopping.train_network(\n",
        "      stock_values,\n",
        "      current_payoff ,\n",
        "      future_payoff)\n",
        "\n",
        "    inputs = stock_values\n",
        "    stopping_probability = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "v1c9hUTGBzcz",
        "outputId": "1ea206fc-39d9-4a85-ee0b-2304287abc91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50, 500, 10)\n"
          ]
        }
      ],
      "source": [
        "# generate underlying stochastic process\n",
        "\n",
        "hyperparam_test_stock_models = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':5000, 'periods': 49, 'maturity': 3., 'strike' : 100,'assets':10,  'spot':90,}\n",
        "S = GBM(**hyperparam_test_stock_models)\n",
        "X=S.simulate_process()\n",
        "\n",
        "\n",
        "\n",
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()   \n",
        "\n",
        "draw_stock_model(X)   \n",
        "print(X.shape) # (date, path, asset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "nzP8sWSG_kG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85dc0a0c-46ec-4d61-d5ff-42ab011ba997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48 : 0.34570861128026115  ,  0.9358992005086402  ,  498\n",
            "47 : 0.0005054265530017671  ,  0.9987741564239923  ,  325\n",
            "46 : 0.0018770426138907843  ,  0.997807040931647  ,  353\n",
            "45 : 5.053465493283839e-05  ,  0.9999919532717662  ,  310\n",
            "44 : 6.572658042791239e-05  ,  0.9993175555569496  ,  361\n",
            "43 : 1.7818500390884488e-05  ,  0.9985326192029871  ,  366\n",
            "42 : 1.0115974513255752e-05  ,  0.9976045539678081  ,  387\n",
            "41 : 4.095523245310271e-08  ,  0.9975818053300192  ,  389\n",
            "40 : 9.112992413623552e-09  ,  0.9981342666606743  ,  441\n",
            "39 : 1.0331134425167235e-13  ,  0.9996342294094099  ,  346\n",
            "38 : 0.00411251761914652  ,  0.9989944892692377  ,  490\n",
            "37 : 1.0280633362508305e-05  ,  0.9964251269560197  ,  476\n",
            "36 : 4.0487991468632006e-16  ,  0.999831359325835  ,  360\n",
            "35 : 1.397821593544696e-10  ,  0.9994847521821082  ,  385\n",
            "34 : 0.28340220164086277  ,  0.9995837147240414  ,  498\n",
            "33 : 2.000607895283779e-05  ,  0.9999728434438592  ,  377\n",
            "32 : 1.208645391338296e-10  ,  0.9999996273659232  ,  360\n",
            "31 : 0.9488780118371546  ,  0.9993005475968972  ,  500\n",
            "30 : 0.19929429321014283  ,  0.9986399019768667  ,  499\n",
            "29 : 0.0009285536533187515  ,  0.9991628653093616  ,  494\n",
            "28 : 0.9771287611620311  ,  0.99904726969346  ,  500\n",
            "27 : 1.4640250144755694e-07  ,  0.9999938043429457  ,  432\n",
            "26 : 0.009215964244560018  ,  0.9998147217310315  ,  496\n",
            "25 : 0.014814269965088873  ,  0.9998398718578085  ,  499\n",
            "24 : 0.5957888512710705  ,  0.9999993593896133  ,  500\n",
            "23 : 0.03592178183500982  ,  0.9999999973585207  ,  425\n",
            "22 : 0.09965374153302393  ,  0.9999974570174233  ,  479\n",
            "21 : 5.5250437341339204e-05  ,  0.9999999998533047  ,  380\n",
            "20 : 1.076360701663257e-06  ,  0.9999999999989901  ,  362\n",
            "19 : 2.3423652019920303e-07  ,  0.9999999999999833  ,  335\n",
            "18 : 3.174519955892692e-05  ,  0.9999997894783003  ,  388\n",
            "17 : 0.0009056527679714128  ,  0.9999916641367071  ,  498\n",
            "16 : 0.048593586957415225  ,  0.9999607899225184  ,  498\n",
            "15 : 0.9965792026664531  ,  0.9999253979061832  ,  500\n",
            "14 : 0.6953808806161584  ,  0.9999830515860235  ,  500\n",
            "13 : 0.0004983945076715542  ,  0.9999999208079149  ,  394\n",
            "12 : 6.965899106051091e-07  ,  0.9999999999381368  ,  362\n",
            "11 : 1.36610331105393e-10  ,  0.9999999999999998  ,  328\n",
            "10 : 2.432813327983573e-07  ,  0.9999998111325664  ,  382\n",
            "9 : 0.0021481442883306942  ,  0.9999946891332538  ,  498\n",
            "8 : 0.49004060967160074  ,  0.9999402249858209  ,  499\n",
            "7 : 0.7673267943378315  ,  0.9999060029920191  ,  500\n",
            "6 : 9.477796387440922e-07  ,  0.9999725185476736  ,  499\n",
            "5 : 1.4042229110004127e-07  ,  0.9999999440175058  ,  481\n",
            "4 : 6.041680184397602e-06  ,  0.9999657525533554  ,  498\n",
            "3 : 0.06851565701138392  ,  0.999997361682459  ,  498\n",
            "2 : 0.9988245635394475  ,  0.9999268488950178  ,  500\n",
            "1 : 0.7816791575918537  ,  0.9999998114328497  ,  500\n",
            "6.414545278570955\n"
          ]
        }
      ],
      "source": [
        "pricing = Recursive(S, Payoff, epochs=50)\n",
        "testing = pricing.price()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "optimal_stopping_V1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}