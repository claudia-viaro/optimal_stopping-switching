{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optimal_switching.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, P)$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t = b_{I_t}X_tdt + \\sigma_{I_t}X_tdW_t\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian otion on a filtered probability space $(\\Omega, \\mathcal{F}, \\mathbf{F}=(\\mathcal{F}_t)_{t \\geq 0} P)$ and $I_t$ is the indicator variable of the regimes valued in $\\mathbf{I}_d = \\{1, \\ldots, d \\}$. $b_i \\in \\mathbf{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$ once in regime $I_t=i$ at time $t$.\n",
        "\n",
        "We will consider a discrete approximization (Euler schema) with respect to. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "X^p_{n,i} = \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\sigma^2_i /2)_{\\mathbf{I}}\\bigtriangleup t + \\sigma_{i, \\mathbf{I}} \\sqrt{\\bigtriangleup t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\bigtriangleup t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ],
      "metadata": {
        "id": "-aX5-o2Sa7nC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yEZA-EFaBd0w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "underlying process - Geometric brownian motion\n",
        "'''\n",
        "\n",
        "class GBM:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, dividend=0):\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-drift * self.dt)\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns array of dimension (paths x periods x assets) \"\"\"\n",
        "    paths = self.paths\n",
        "    path = np.array([self.simulate_one_path() for i in range(paths)]) \n",
        "    return path.reshape(path.shape[0], path.shape[2], path.shape[1])\n",
        "\n",
        "  def drift_fct(self,x):\n",
        "    return  (self.drift-self.delta-0.5*self.sigma**2)* x\n",
        "\n",
        "  def diffusion_fct(self,x):\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "  def simulate_one_path(self):\n",
        "    ''' if a single path '''\n",
        "    path = np.empty((self.assets, self.periods+1))\n",
        "    path[:, 0] = self.spot\n",
        "    for k in range(1, self.periods+1):\n",
        "      random_numbers = np.random.normal(0, 1, self.assets)\n",
        "      dW =(random_numbers*np.sqrt(self.dt))\n",
        "      previous_spots = path[:, k - 1]\n",
        "      diffusion = (self.diffusion_fct(previous_spots))\n",
        "      path[:, k] = (\n",
        "          previous_spots\n",
        "          + self.drift_fct(previous_spots)* self.dt\n",
        "          + diffusion*dW) \n",
        "    return path   "
      ],
      "metadata": {
        "id": "xJbxC0rzBhrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As introduced, the stochastic system can operate in $m$ modes or regimes from the finite set $\\mathbb{I}=\\{1, \\ldots , m \\}$. In this case we consider $m=2$ with $\\mathbb{I}=\\{\\text{on}, \\text{off} \\}$. \n",
        "\n",
        "The regimes can be switched at a sequence of stopping times over a finite horizon $[0, \\ldots , T]$.\n",
        "\n",
        "There is a payoff rate per unit of time when the system is in mode $i \\in \\mathbb{I}$ at time $t$ as a mapping $\\Psi_i(t, X_t): \\Omega \\times [0, T] \\rightarrow \\mathbb{R}$. The payoff function for the call option used is of the form $( \\max_{i \\in \\{ 1, \\ldots , d \\}} X_t^i - K) ^{+}$, where $K$ is the strike price at any point in the time grid $0 = t_0 < t_1 < \\ldots < t_N = T$. the system also outputs a final reward for being in mode $i \\in \\mathbb{I}$ at time $T$ given by $\\Gamma_i$.\n",
        "\n",
        "There is a cost for switching from regime $i$ to $j$ given by the function $\\gamma_{i, j} : \\Omega \\times [0, T] \\rightarrow \\mathbb{R} $ to cover for the extra costs due to the change of the regime.\n",
        "\n",
        "A strategy $\\alpha$ for the power plant will be a combination of two sequences:\n",
        "- non decreasing sequence of $\\mathbb{F}$-stopping times $(\\tau_n)_{n \\geq 1}$, $n \\in \\mathbb{N} \\backslash \\{0\\}$, where at $\\tau_n$ the production is swithced from the current mode $i$ to $j$. we also assume: $\\tau_0=t$ and $\\tau_n \\leq \\tau_{n+1}$.\n",
        "- a sequence of indicators $(\\iota)_{n \\geq 1}$, $n \\in \\mathbb{N} \\backslash \\{0\\}$, $\\mathcal{F}_{\\tau_n}$- measurable valued in $\\mathbb{I}_m$. At time $t=\\tau_n$ the system is switched from the current regime $\\iota_{n-1}$ to $\\iota_{n}$, with $\\iota_{0}=i$.\n",
        "\n",
        "We denote by $\\mathcal{A}_{t, i}$ the set of admissible strategies to switch at time $\\tau_n$, $n \\geq 1$, from the current regime $\\iota_{n-1}$ to $\\iota_{n}$. \n"
      ],
      "metadata": {
        "id": "yqmbYE_8z_fe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For any initial condition $(x, i) \\in [0, T] \\times \\mathbb{I}_m$, and any control $\\alpha=(\\tau_n, \\iota_n)_{n \\leq 0} \\in \\mathcal{A}_{t, i}$. the total expected payoff up to $T$ for such strategy can be expressed as: \n",
        "\\begin{equation}\n",
        "J_i(x, \\alpha) = \\mathbb{E} \\Big[ \\sum_{s=t}^{T-1} \\Psi(X_t^{x, i}, I_t^i) + \\Gamma - \\sum_{n \\leq 1}\\gamma_{\\iota_{n-1}, \\iota_n} \\mathbf{1}_{ \\{ \\tau_n < T \\} }  | \\mathcal{F}_n   \\Big]\n",
        "\\end{equation}\n",
        "\n",
        "The objective is to maximize this expected total profit for all strategies $\\alpha$. For this purpose, we set the value function:\n",
        "\\begin{equation}\n",
        "V_i(x)=\\sup_{\\alpha \\in \\mathcal{A}} J_i(x, \\alpha) \\;\\;\\;\\;\\;\\;\\;\\;\\; \\forall \\alpha \\in \\mathcal{A}_{t, i} \\,\\, \\mathbb{P}\\; a.s. \n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "KsWsO53nz_lG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Following Becker, Cheridito and Jentzen, we reformulate stopping time problem into a sequence of $0-1$ stopping decisions. To optimally stop the Markov process $X$ we make stopping decisions according to $f_n(X_n)$ for measurable functions $f_n: \\mathbb{R}^d â†’ \\{0, 1 \\}, n \\in \\mathbb{N}$. By construction $f_N \\equiv 1$ as at $n=N$ there is a terminal stopping decision where $\\tau_N \\equiv N$. \n",
        "\n",
        "Given $n \\in \\{0, 1, \\ldots, N-1 \\}$ and the final stopping decision, let $\\tau_{n+1}$ be a stopping time in $\\mathcal{T}_{n+1}$ of the form:\n",
        "\\begin{equation}\n",
        "\\tau_{n+1} = \\sum_{m=n+1}^N m f_m(X_m) \\prod _{j=n+1}^{m-1} (1-f_j(X_j))\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "To approach the problem, we iteratively approximate the optimal stopping decisions $f_n: \\mathbb{R}^d \\rightarrow \\{0, 1 \\}, n = \\{ 1, 2, \\ldots, N-1 \\}$, by a neural network $f^{\\theta}: \\mathbb{R}^d \\rightarrow \\{0, 1 \\}$ with parameter $\\theta \\in \\mathbb{R}^q$. We choose $\\theta_N \\in \\mathbb{R}^q$ such that $f^{\\theta}_N \\equiv 1$ and determine $\\theta_n \\in \\mathbb{R}^q$ for $n \\leq N-1$ by recursion of the form:\n",
        "\n",
        "\\begin{equation}\n",
        "\\tau_{n+1} = \\sum_{m=n+1}^N m f^{\\theta_m}(X_m) \\prod _{j=n+1}^{m-1} (1-f^{\\theta_j}(X_j))\n",
        "\\end{equation}\n",
        "\n",
        "Since $f^{\\theta}$ takes values in $\\{ 0,1 \\}$, hence not appropriate for a gradient-descent optimization method, the neural network includes a layer performing a logostic transformation such that we have the resulting output function $F^{\\theta}: \\mathbb{R}^d \\rightarrow (0,1)$.\n",
        "\n",
        "The Neural network includes $(d+40)$ hidden units and comprises a combination of linear and rectified linear activation functions. "
      ],
      "metadata": {
        "id": "lTuPqVNSVB-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Neural network\n",
        "'''\n",
        "\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets, hidden_size):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    self.l1 = nn.Linear(assets, hidden_size) \n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, 1)  \n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l3(out)\n",
        "    out = self.sigmoid(out)\n",
        "\n",
        "    return out\n",
        "\n",
        "\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    # torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "MpTiRUxLBj5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Train the neural network\n",
        "'''\n",
        "\n",
        "class Train_Network(object):\n",
        "\n",
        "  def __init__(self, assets, paths, hidden_size, epochs=20, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets, hidden_size=self.assets+40).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "  def _Loss(self, X):\n",
        "    return -torch.mean(X)\n",
        "\n",
        "  def train_network(self,  stock_values, immediate_exercise_value,\n",
        "                    discounted_next_values):\n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    discounted_next_values = torch.from_numpy(discounted_next_values).double()\n",
        "    immediate_exercise_value = torch.from_numpy(immediate_exercise_value).double()\n",
        "    inputs = stock_values\n",
        "    X_inputs = torch.from_numpy(inputs).double()\n",
        "\n",
        "    self.network.train(True)\n",
        "    ones = torch.ones(len(discounted_next_values))\n",
        "    for epoch in range(self.epochs):\n",
        "      for batch in tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=self.batch_size, drop_last=False):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = self.network(X_inputs[batch]).reshape(-1) # probabilities\n",
        "        values = (immediate_exercise_value[batch].reshape(-1)[0] * outputs +\n",
        "                    discounted_next_values[batch] * (ones[batch] - outputs))\n",
        "        loss = self._Loss(values)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "  def evaluate_network(self, X_inputs):\n",
        "    self.network.train(False)\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()[0]).detach().numpy()"
      ],
      "metadata": {
        "id": "ARr530-tBreb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate underlying stochastic process\n",
        "_STOCK_MODELS = {\"BlackScholes\": GBM,}\n",
        "hyperparam_test_stock_models = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':4, 'periods': 3, 'maturity': 3., 'assets':10,  'spot':90,}\n",
        "stock_model_switching = _STOCK_MODELS[\"BlackScholes\"](**hyperparam_test_stock_models)\n",
        "drift= 0.2; sigma= 0.05; delta= 0.1; paths=1; periods=3; maturity= 3; assets=1; spot=90; regime=2; strike=90\n",
        "disc_factor = np.math.exp((-drift) * maturity/(periods))\n",
        "stock_paths = stock_model_switching.simulate_process() # shape (1, 4, 1)\n",
        "\n",
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[0, :, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()   \n",
        "\n",
        "draw_stock_model(stock_paths)    \n",
        "print(stock_paths)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 898
        },
        "id": "v1c9hUTGBzcz",
        "outputId": "45d36056-c8eb-4351-f454-68e9eb20376a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 90.          95.5953999  105.61843508 111.22060835  90.\n",
            "   102.64972517 115.82297642 126.45137768  90.          97.19614849]\n",
            "  [100.52157754 112.16534216  90.          97.0034381  108.14743016\n",
            "   113.5713288   90.         102.071225   110.18659785 110.94685601]\n",
            "  [ 90.         105.51902094 117.28957928 128.49902562  90.\n",
            "    96.34354252 105.64229116 125.55769572  90.          92.83609216]\n",
            "  [110.74424711 124.4784162   90.          96.39304493 112.67626621\n",
            "   124.15463253  90.          90.76548998  94.35817489 105.26685185]]\n",
            "\n",
            " [[ 90.          97.62912614 110.28224834 131.02165233  90.\n",
            "    91.92754984  95.62085035  96.84716797  90.         100.06142597]\n",
            "  [117.25489293 133.89927321  90.          95.05423536  99.53732046\n",
            "   119.11885552  90.          99.81249097 106.513045   122.40302335]\n",
            "  [ 90.          94.63521195 107.58510208 127.48152043  90.\n",
            "    89.462402   100.07329749 102.97763526  90.          94.74477467]\n",
            "  [109.43287432 123.71956637  90.          99.07684124 114.1327272\n",
            "   136.00159348  90.         107.65689047 120.33320302 124.30412316]]\n",
            "\n",
            " [[ 90.          95.27258973 101.42761659 109.85213344  90.\n",
            "    97.15861353 107.38290038 115.74111639  90.          94.15174701]\n",
            "  [ 97.48788519  99.39429318  90.         107.32897054 119.24112787\n",
            "   125.59725297  90.         103.72175511 111.58324938 126.11884691]\n",
            "  [ 90.          97.17784908 106.15387823 123.52186567  90.\n",
            "    91.7310551   98.0236927  107.20288947  90.          97.24089575]\n",
            "  [107.83053097 124.94914869  90.          98.23187197 103.81853116\n",
            "   113.66634922  90.          92.05378446  97.98315512 112.88628964]]\n",
            "\n",
            " [[ 90.          92.50985854  96.70173487 107.01867847  90.\n",
            "    96.05245957 108.63202207 115.23822085  90.         106.18578832]\n",
            "  [115.05545888 125.12881303  90.         103.73529695 118.66085042\n",
            "   138.7542827   90.         103.68043056 106.80326814 108.21997863]\n",
            "  [ 90.          98.14579197 119.19889056 130.53413564  90.\n",
            "    95.07322874  98.82191711 111.47610359  90.          98.9447996 ]\n",
            "  [108.32001607 128.08946142  90.         100.67417385 112.59088755\n",
            "   132.99821867  90.          94.29808527 108.66978216 120.85680061]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Define a function gamma(i, j) for the switching cost\n",
        "'''\n",
        "\n",
        "def switching_cost(payoff, eta = 0.02):\n",
        "  cost = np.array([np.sqrt(eta*payoff)+np.tanh(eta)*np.sqrt(eta*payoff)+np.random.randn(), np.sqrt(eta*payoff)+np.tanh(eta)+np.random.randn()])\n",
        "  return cost     \n",
        "\n",
        "'''\n",
        "Define an objective function\n",
        "'''\n",
        "\n",
        "def objective_f(X,Y, tau, disc_factor, date, path):\n",
        "  Y=X*np.exp((date-tau)*disc_factor) + Y[date+1, path,:]- np.squeeze(switching_cost(X), axis=(1,)) \n",
        "  return Y  \n",
        "\n",
        "'''\n",
        "Define a payoff function\n",
        "[more options can be set]\n",
        "'''\n",
        "\n",
        "class Eval:\n",
        "  def payoff(self, X):\n",
        "    raise NotImplemented()\n",
        "\n",
        "class MaxCall(Eval):\n",
        "  def __init__(self, strike):\n",
        "    self.strike =  strike\n",
        "\n",
        "  def payoff(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None) \n",
        "\n",
        "class RunningBenefit(Eval):\n",
        "\n",
        "  def objective_f(X,Y, tau, disc_factor, date, path):\n",
        "    Y=X*np.exp((date-tau)*disc_factor) + Y[date+1, path,:]- np.squeeze(switching_cost(X), axis=(1,)) \n",
        "    return Y  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRYgMuM2C_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the cases of intermediate time steps $t_0, t_1, t_2$\n",
        "- at $t=3$\n",
        "\n",
        "- at $t=2$:\n",
        "  - produce a stopping rule at t2\n",
        "  - update f_theta and tau\n",
        "  - if F_theta = 1:\n",
        "    - compute \n",
        "  \n",
        "$$ Y_{i,2} = \\Psi_i(2) + \\max[ Y_{j,2} - \\gamma_{i,j}(2) ] $$ <br>\n",
        "$$ Y_{j,2} = \\Psi_j(2) + \\max [ Y_{i,2} - \\gamma_{j,i}(2) ] $$\n",
        "\n",
        "  - if $F_{\\theta} = 0$:\n",
        "    - compute $Y_{i,2} = \\Psi_i(2)$ and $Y_{j,2} = \\Psi_j(2)$\n",
        "\n",
        "- at $t=1$, $t=0$ the same <br>\n",
        "\n",
        "$\\Psi_{i,j}(t)=$ running benefit function -> payoff function  <br>\n",
        "$\\gamma_{i,j}(t) =$ switching cost function -> what?                       \n"
      ],
      "metadata": {
        "id": "worQD8DMKxhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Recursive:\n",
        "  def __init__(self, process, eval, epochs=20,  hidden_size=10):\n",
        "\n",
        "    self.process = process\n",
        "\n",
        "    payoff=\"MaxCall\"          \n",
        "    runningbenefit = \"RunningBenefit\"\n",
        "    self.payoff = eval[payoff](strike)\n",
        "    self.runningbenefit = eval[runningbenefit]\n",
        "\n",
        "\n",
        "    state_size = process.assets\n",
        "    self.neural_stopping = Train_Network(state_size, process.paths, hidden_size=hidden_size)\n",
        "\n",
        "  def price(self):\n",
        "    \"\"\"It computes the price of an American Option using a backward recusrion.\n",
        "    \"\"\"\n",
        "    process = self.process\n",
        "    stock_paths = self.process.simulate_process()\n",
        "    \n",
        "    disc_factor = np.math.exp((-process.drift) * process.maturity/(process.periods))\n",
        "    \n",
        "    ''' \n",
        "    create empty objects to store values \n",
        "    '''\n",
        "    # Vmat will contain value function estimates\n",
        "    # value function estimate should distinguish the two types of regimes too\n",
        "    Y_it=np.zeros((periods+1,paths, regime))\n",
        "    #print(\"shape Y_it\",Y_it.shape) #(4, 1, 2)\n",
        "    # Y_it will take mean of Y_it estimates across paths (for each regime)\n",
        "    Y_it_mean=np.zeros((periods+1, regime))\n",
        "    Y_it_std = np.zeros((periods+1, regime))\n",
        "    #print(\"shape Y_it_est\",Y_it_estimate.shape) #(4, 2)\n",
        "\n",
        "    # Fmatrix records stopping decisions \n",
        "    F_theta=np.zeros((periods+1,paths, regime))\n",
        "    F_theta[periods,:,:]=1 # at maturity we switch\n",
        "    #print(\"f_theta \",f_theta.shape) #(4, 1, 2)\n",
        "\n",
        "    #tau matrix will record stopping times, at maturity we assume the process stops\n",
        "    # once a stopping decision is recorded, we take the time at which the stopping decision occured (hence the stopping time)\n",
        "    tau_list=np.zeros((periods+1,paths, regime))\n",
        "    tau_list[periods,:,:]=periods\n",
        "\n",
        "    # for N=N\n",
        "    payoff_N = self.payoff.payoff(stock_paths[:, -1, :]) # payoff of the last date --- \\gamma_i or \\gamma_j\n",
        "    payoff_0 = self.payoff.payoff(stock_paths[:, 0, :])  #[0] #initial payoff   \n",
        "    payoff_N =np.reshape(np.repeat(payoff_N, 2, axis=0),(process.paths,2)) \n",
        "\n",
        "    Y_it[periods,:,:]=payoff_N*disc_factor*periods #PV terminal exercise price\n",
        "    Y_it_mean[periods]=np.mean(Y_it[periods,:,:])\n",
        "    values = payoff_N\n",
        "\n",
        "\n",
        "    # recursive calc, from n=N-1 to 0 with steps of -1\n",
        "\n",
        "\n",
        "    for date in range(stock_paths.shape[1] - 2, 0, -1):\n",
        "      f_theta = self.switch(stock_paths[:, date, :],\n",
        "                            payoff_N.reshape(-1, 1), \n",
        "                            values*disc_factor)\n",
        "      F_theta[date,:,:]=(f_theta > 0.5)*1.0   # 0-1 decision\n",
        "      tau_list[date,:,:]=np.argmax(F_theta, axis=0)\n",
        "\n",
        "      for path in range(0, paths):\n",
        "        \n",
        "        tau = tau_list[date,path,:]\n",
        "        running_benefit = self.payoff.payoff(np.expand_dims(stock_paths[path, int(tau[0]), :], axis=0))\n",
        "        Y_it[date,path:]=self.runningbenefit.objective_f(running_benefit, Y_it, int(tau[0]), disc_factor, date, path)\n",
        "      \n",
        "      Y_it_mean=np.mean(Y_it, axis=1) # mean by row of the paths\n",
        "      Y_it_std=np.std(Y_it, axis=1) # std by row of the paths\n",
        "\n",
        "\n",
        "\n",
        "      \n",
        "      #maxi = np.max(np.array([np.mean(payoff_0), np.mean(Y_it_mean, axis=0)]))  \n",
        "      spot_payoff = np.mean(payoff_0)\n",
        "    return {'mean': np.mean(Y_it_mean, axis=0), 'sd':  np.mean(Y_it_mean, axis=0),'SE': np.mean(Y_it_mean, axis=0)/(np.sqrt(process.paths)), 'spot_payoff' : spot_payoff, 'estimates' : Y_it }\n",
        "\n",
        "\n",
        "  def switch(self, inputs, immediate_exercise_values,\n",
        "           discounted_next_values):\n",
        "    self.neural_stopping.train_network(\n",
        "        inputs,\n",
        "        immediate_exercise_values.reshape(-1, 1),\n",
        "        discounted_next_values)\n",
        "\n",
        "    switch = self.neural_stopping.evaluate_network(inputs)\n",
        "    return switch      \n",
        "\n",
        "  def switching_cost(payoff, eta = 0.02):\n",
        "    cost = np.array([np.sqrt(eta*payoff)+np.tanh(eta)*np.sqrt(eta*payoff)+np.random.randn(), np.sqrt(eta*payoff)+np.tanh(eta)+np.random.randn()])\n",
        "    return cost    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yQtkD5yJCx75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths=hyperparam_test_stock_models['paths']\n",
        "drift=hyperparam_test_stock_models['drift']\n",
        "spot=hyperparam_test_stock_models['spot']\n",
        "sigma=hyperparam_test_stock_models['sigma']\n",
        "maturity=hyperparam_test_stock_models['maturity']\n",
        "assets=hyperparam_test_stock_models['assets']\n",
        "periods=hyperparam_test_stock_models['periods']\n",
        "strike=90\n",
        "\n",
        "\n",
        "epochs=10\n",
        "hidden_size=10\n",
        "\n",
        "_EVAL = {\"MaxCall\": MaxCall,\n",
        "            \"RunningBenefit\": RunningBenefit,\n",
        "           }\n",
        "\n",
        "_ALGOS = {\"DOS\": Recursive, \n",
        "          }\n",
        "algo=\"DOS\"\n",
        "payoff=\"MaxCall\"\n",
        "\n",
        "_PAYOFFS = {\"MaxCall\": MaxCall,\n",
        "           }\n",
        "        \n",
        "payoff_ = _PAYOFFS[payoff](strike)\n",
        "pricing = _ALGOS[algo](stock_model_switching, _EVAL, epochs=epochs,hidden_size=hidden_size)"
      ],
      "metadata": {
        "id": "nzP8sWSG_kG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_switch = pricing.price()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "TRw55KflCn0K",
        "outputId": "a6d633a7-00de-45e1-a998-dc72e4d40543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-086e4262aa5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprice_switch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpricing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-a9bdad4efb0c>\u001b[0m in \u001b[0;36mprice\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m       f_theta = self.switch(stock_paths[:, date, :],\n\u001b[1;32m     60\u001b[0m                             \u001b[0mpayoff_N\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                             values*disc_factor)\n\u001b[0m\u001b[1;32m     62\u001b[0m       \u001b[0mF_theta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_theta\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1.0\u001b[0m   \u001b[0;31m# 0-1 decision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m       \u001b[0mtau_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF_theta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-a9bdad4efb0c>\u001b[0m in \u001b[0;36mswitch\u001b[0;34m(self, inputs, immediate_exercise_values, discounted_next_values)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mimmediate_exercise_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         discounted_next_values)\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mswitch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_stopping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-6dc7344ca794>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(self, stock_values, immediate_exercise_value, discounted_next_values)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         values = (immediate_exercise_value[batch].reshape(-1)[0] * outputs +\n\u001b[0;32m---> 36\u001b[0;31m                     discounted_next_values[batch] * (ones[batch] - outputs))\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the objects\n",
        "\n",
        "Mean_est_dos = 'mean'\n",
        "Sd_est_dos = 'sd'\n",
        "SE_est_dos = 'SE'\n",
        "pay0_dos = 'spot_payoff'\n",
        "matrix = 'matrix'\n",
        "\n",
        "Mean_estimate_dos = price_switch.get(Mean_est_dos, 0)\n",
        "Sd_estimate_dos = price_switch.get(Sd_est_dos, 0)\n",
        "SE_estimate_dos = price_switch.get(SE_est_dos, 0)\n",
        "payoff0_dos = price_switch.get(pay0_dos, 0)\n",
        "matrix_results = price_switch.get(matrix)\n",
        "\n",
        "z=scipy.stats.norm.ppf(0.975)\n",
        "lower=Mean_estimate_dos - z*Sd_estimate_dos\n",
        "upper=Mean_estimate_dos + z*Sd_estimate_dos\n",
        "\n",
        "dates = np.array([i for i in range(len(Mean_estimate_dos))])\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(dates,Mean_estimate_dos)\n",
        "ax.fill_between(dates, (Mean_estimate_dos-z*Sd_estimate_dos), (Mean_estimate_dos+z*Sd_estimate_dos), color='b', alpha=.1)\n",
        "plt.xlabel(\"Dates\")\n",
        "plt.ylabel(\"Value\")\n",
        "\n",
        "print(matrix_results)"
      ],
      "metadata": {
        "id": "KY7yIrCgJ2YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def switch(inputs, immediate_exercise_values,\n",
        "           discounted_next_values):\n",
        "    neural_stopping.train_network(\n",
        "        inputs,\n",
        "        immediate_exercise_values.reshape(-1, 1),\n",
        "        discounted_next_values)\n",
        "\n",
        "    switch = neural_stopping.evaluate_network(inputs)\n",
        "    return switch\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cq38_8v5eC8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# open up the code, some things are not working\n",
        "# first make it work for paths>1\n",
        "\n",
        "# Vmat will contain value function estimates\n",
        "# value function estimate should distinguish the two types of regimes too\n",
        "Y_it=np.zeros((periods+1,paths, regime))\n",
        "#print(\"shape Y_it\",Y_it) #(4, 4, 2)\n",
        "# Y_it will take mean of Y_it estimates across paths (for each regime)\n",
        "Y_it_mean=np.zeros((periods+1, regime))\n",
        "Y_it_std = np.zeros((periods+1, regime))\n",
        "#print(\"shape Y_it_est\",Y_it_estimate.shape) #(4, 2)\n",
        "\n",
        "# Fmatrix records stopping decisions \n",
        "F_theta=np.zeros((periods+1,paths, regime))\n",
        "F_theta[periods,:,:]=1 # at maturity we switch\n",
        "#print(\"f_theta \",f_theta.shape) #(4, 1, 2)\n",
        "\n",
        "#tau matrix will record stopping times, at maturity we assume the process stops\n",
        "# once a stopping decision is recorded, we take the time at which the stopping decision occured (hence the stopping time)\n",
        "tau_list=np.zeros((periods+1,paths, regime))\n",
        "tau_list[periods,:,:]=periods\n",
        "\n",
        "process = _STOCK_MODELS[\"BlackScholes\"](**hyperparam_test_stock_models)\n",
        "stock_paths = process.simulate_process()\n",
        "_EVAL = {\"MaxCall\": MaxCall,\n",
        "            \"RunningBenefit\": RunningBenefit,\n",
        "           }\n",
        "payoff=\"MaxCall\"          \n",
        "runningbenefit = \"RunningBenefit\"\n",
        "payoff = _EVAL[payoff](strike)\n",
        "runningbenefit = _EVAL[runningbenefit]\n",
        "state_size = process.assets\n",
        "neural_stopping = OptimalStoppingOptimization(state_size, process.paths, hidden_size=hidden_size) \n",
        "\n",
        "# for N=N\n",
        "payoff_N = payoff.payoff(stock_paths[:, -1, :]) # payoff of the last date --- \\gamma_i or \\gamma_j\n",
        "payoff_0 = payoff.payoff(stock_paths[:, 0, :])  #[0] #initial payoff   \n",
        "payoff_N =np.reshape(np.repeat(payoff_N, 2, axis=0),(process.paths,2))\n",
        "\n",
        "Y_it[periods,:,:]=payoff_N*disc_factor*periods #PV terminal exercise price\n",
        "Y_it_mean[periods]=np.mean(Y_it[periods,:,:])\n",
        "values = payoff_N\n",
        "print(values)\n",
        "\n",
        "# for smaller n\n",
        "date=2\n",
        "print(stock_paths[:, date, :])\n",
        "print(stock_paths)\n",
        "\n",
        "network = NetworkDOS(process.assets, hidden_size=process.assets+40).double()\n",
        "network.apply(init_weights)\n",
        "optimizer = optim.Adam(network.parameters())\n",
        "discounted_next_values = torch.from_numpy(payoff_N.reshape(-1, 1)).double()\n",
        "\n",
        "immediate_exercise_value = torch.from_numpy(values*disc_factor).double()\n",
        "print(\"immediate\", immediate_exercise_value)\n",
        "inputs = stock_paths[:, date, :]\n",
        "X_inputs = torch.from_numpy(inputs).double() #just a tensor\n",
        "\n",
        "\n",
        "network.train(True)\n",
        "ones = torch.ones(len(discounted_next_values))\n",
        "batch_size=200\n",
        "\n",
        "\n",
        "batch=2\n",
        "epoch=3\n",
        "\n",
        "\n",
        "optimizer.zero_grad()\n",
        "outputs = network(X_inputs[batch]).reshape(-1) # probabilities\n",
        "values = (immediate_exercise_value[batch].reshape(-1) * outputs +\n",
        "            discounted_next_values[batch] * (ones[batch] - outputs))\n",
        "print(immediate_exercise_value[batch].reshape(-1)*outputs)\n",
        "print(immediate_exercise_value[batch].reshape(-1)[0]*outputs)\n",
        "\n",
        "print(discounted_next_values[batch].size)\n",
        "print((ones[batch] - outputs).size)\n",
        "#print(\"values\", values)\n",
        "\n",
        "'''\n",
        "for date in range(stock_paths.shape[1] - 2, 0, -1):\n",
        "  f_theta = switch(stock_paths[:, date, :],\n",
        "                        payoff_N.reshape(-1, 1), \n",
        "                        values*disc_factor)\n",
        "  F_theta[date,:,:]=(f_theta > 0.5)*1.0   # 0-1 decision\n",
        "  tau_list[date,:,:]=np.argmax(F_theta, axis=0)\n",
        "\n",
        "  for path in range(0, paths):\n",
        "    \n",
        "    tau = tau_list[date,path,:]\n",
        "    running_benefit = payoff.payoff(np.expand_dims(stock_paths[path, int(tau[0]), :], axis=0))\n",
        "    Y_it[date,path:]= runningbenefit.objective_f(running_benefit, Y_it, int(tau[0]), disc_factor, date, path)\n",
        "  \n",
        "  Y_it_mean=np.mean(Y_it, axis=1) # mean by row of the paths\n",
        "  Y_it_std=np.std(Y_it, axis=1) # std by row of the paths\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "  #maxi = np.max(np.array([np.mean(payoff_0), np.mean(Y_it_mean, axis=0)]))  \n",
        "  spot_payoff = np.mean(payoff_0)\n",
        "\n",
        "print(\"Ftheta\", F_theta)\n",
        "print(\"tau\", tau)\n",
        "print(\"tau_list\", tau_list)\n",
        "print(\"Y_it\", Y_it)\n",
        "print(\"Y_it_std\",Y_it_std)\n",
        "'''"
      ],
      "metadata": {
        "id": "6IobdYi5drnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "KSV0XsBha4V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=20; batch_size=2000\n",
        "network = NetworkDOS(process.assets, hidden_size=process.assets+40).double()\n",
        "network.apply(init_weights)\n",
        "\n",
        "def train_network(stock_values, immediate_exercise_value,\n",
        "                    discounted_next_values):\n",
        "    optimizer = optim.Adam(network.parameters())\n",
        "    discounted_next_values = torch.from_numpy(discounted_next_values).double()\n",
        "    immediate_exercise_value = torch.from_numpy(immediate_exercise_value).double()\n",
        "    inputs = stock_values\n",
        "    X_inputs = torch.from_numpy(inputs).double()\n",
        "\n",
        "    network.train(True)\n",
        "    ones = torch.ones(len(discounted_next_values))\n",
        "    for epoch in range(epochs):\n",
        "      for batch in tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=batch_size, drop_last=False):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = network(X_inputs[batch]).reshape(-1) # probabilities\n",
        "        values = (immediate_exercise_value[batch].reshape(-1)[0] * outputs +\n",
        "                    discounted_next_values[batch] * (ones[batch] - outputs))\n",
        "        \n",
        "        loss = -torch.mean(values)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def evaluate_network(X_inputs):\n",
        "  network.train(False)\n",
        "  X_inputs = torch.from_numpy(X_inputs).double()\n",
        "  outputs = network(X_inputs)\n",
        "  return outputs.view(X_inputs.size()[0]).detach().numpy()\n",
        "\n",
        "\n",
        "neural_stopping.train_network(\n",
        "        stock_paths[:, date, :],\n",
        "        payoff_N.reshape(-1, 1),\n",
        "        values*disc_factor)\n",
        "switch = neural_stopping.evaluate_network(stock_paths[:, date, :])  "
      ],
      "metadata": {
        "id": "GfvJ4rBkGdsz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}