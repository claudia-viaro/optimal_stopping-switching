{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opt_switching_V3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPl/Da8wZYzUhFFgCC7dVFq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_stopping-switching/blob/main/optimal_switching/opt_switching_V3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we fix the final regime of the process"
      ],
      "metadata": {
        "id": "1sjUHwhxLQUC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, P)$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t = b_{I_t}X_tdt + \\sigma_{I_t}X_tdW_t\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian motion on a filtered probability space $(\\Omega, \\mathcal{F}, \\mathbf{F}=(\\mathcal{F}_t)_{t \\geq 0} P)$ and $I_t$ is the indicator variable of the regimes valued in $\\mathbf{I}_d = \\{1, \\ldots, d \\}$. $b_i \\in \\mathbf{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$ once in regime $I_t=i$ at time $t$.\n",
        "\n",
        "We will consider a discrete approximization (Euler schema) with respect to. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "X^p_{n,i} = \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\sigma^2_i /2)_{\\mathbf{I}}\\Delta t + \\sigma_{i, \\mathbf{I}} \\sqrt{\\Delta t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\Delta t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ],
      "metadata": {
        "id": "sNSqonJN66zF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QsjSbJxO9nQV"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackScholes:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths, self.assets ))\n",
        "\n",
        "    spot_paths[0, :, :] = self.spot\n",
        "    random_numbers = np.random.normal(0, 1, (self.periods, paths, self.assets ))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1), self.assets, axis=2)\n",
        "    sig = np.ones((self.periods, paths, self.assets))*self.sigma\n",
        "    \n",
        "    spot_paths[1:, :,  :] = np.repeat(\n",
        "        spot_paths[0:1, :, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])\n",
        "\n",
        "\n",
        "'''\n",
        "PLOT\n",
        "'''\n",
        "\n",
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()"
      ],
      "metadata": {
        "id": "kRvtM2Fl9qTd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We employ a neural network to approximate the stopping decision functions $\\{f_n\\}_{n=0}^N$ by constructing a sequence of neural networks of the form $f^{\\theta_n}:\\mathbb{R}^d → \\{0,1\\}$ with parameters $\\theta_n \\in \\mathbb{R}^q$ to approximate $f_n$.\n",
        "\n",
        "\n",
        "In its basic form, a neural network is composed of several layers, and layers are made of nodes. From the picture below, we can observe that a node combines input from the data, $x_{1:n}$, with a set of weights, $w_{1:n}$, that either amplify or dampen that input, thereby assigning significance to inputs with regard to the task the algorithm is trying to learn. $x_{1:n}$ are either the inputs of the overall network if this node is in the first layer or the outputs from the previous layer. Then, the input-weight products are summed, usually with a bias term, and the sum is passed through a node’s so-called activation function $f$, to determine whether and to what extent that signal should progress further through the network to affect the ultimate outcome (depending on the magnitude of each associated weight $w_i$). If the signals passes through, we can say that the neuron has been “activated” and returns an output.\n",
        "\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1rButBJka1QjKsLSrAWgJKrxNCGdntf-K)\n",
        "\n",
        "Generally, NNs comprise multiple node layers through which data is passed, giving rise to what can be referred to as the depth of a neural network. In such networks, each layer of nodes trains on a distinct set of features based on the previous layer’s output. The further we move into the neural net, the more complex the features can be recognized by the nodes, since they aggregate and recombine features from the previous layer.\n",
        "\n",
        "![](https://drive.google.com/uc?export=view&id=1b8Hbzn5xahE9jHf5jgIslG3dedkLAHst)\n",
        "\n",
        "The neural network used here takes the form $F^{\\theta}: \\mathbb{R}^d → (0,1)$ for $\\theta \\in \\{\\theta_0, \\ldots, \\theta_N  \\}$, that is the parameters are trained via a neural network that outputs probabilities in the interval $(0,1)$. This is due to the fact that the G-B optimization algorithm is to be applied to a continuous function with respect to $\\theta_n$, which $f^{\\theta_n}$ is not. Hence, the multi-layer, feed-forward neural network takes the form:\n",
        "\n",
        "\\begin{equation}\n",
        "F^{\\theta}= \\psi \\circ a_3^{\\theta} \\circ \\phi_{q_2} \\circ a_2^{\\theta} \\circ \\phi_{q_1} \\circ a_1^{\\theta}\n",
        "\\end{equation}\n",
        "where \n",
        "\n",
        "-  $q_1, q_2$ are the number of nodes in the hidden layers\n",
        "- $a_1^{\\theta} : \\mathbb{R}^d → \\mathbb{R}^{q_1}, a_2^{\\theta}: \\mathbb{R}^{q_1} → \\mathbb{R}^{q_2}$ are linear transformation functions: $a_i^{\\theta}(x)=W_i x + b_i$ with matrices $W_1 \\in \\mathbb{R}^{q_1 \\times d}, W_2 \\in \\mathbb{R}^{q_2 \\times q_1}, W_3 \\in \\mathbb{R}^{q_2 \\times 1}$ and vectors $b_1 \\in \\mathbb{R}^{q_1}, b_2 \\in \\mathbb{R}^{q_2}, b_3 \\in \\mathbb{R}^{1}$.\n",
        "- $\\phi_{q_i}: \\mathbb{R}^{q_i}$ is the ReLU activation function: $\\phi_{q_1}(x_i, \\ldots, x_{q_i})=(x_i^{+}, \\ldots, x_{q_i}^{+})$\n",
        "- $\\psi = \\mathbb{R} → \\mathbb{R}$ is the logistic sigmoid function: $\\psi(x)=1/(1+ e^{-x})$.\n",
        "Between the layers a batch normalization is also added, it takes the output from the previous layer and normalizes it before sending it to the next layer. This has the effect of stabilizing the neural network. \n",
        "\n",
        "The parameters will comprise $\\theta = \\{W_1, W_2,, W_3, b_1, b_2, b_3\\}\\in \\mathbb{R}^q$, where $q=q_1(d+q_2+1)+2q_2+1$. The value of $d$ stands for the dimension, that is the number of assets and will be varied among $d=\\{2,4, 5, 10, 20\\}. \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MbI9kTmBCcAd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = assets + 40\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.a1 = nn.Linear(assets, H)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.a3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "  def forward(self, input):\n",
        "    out = self.bn0(input)\n",
        "    out = self.a1(out)\n",
        "\n",
        "    out = self.relu(out)\n",
        "    out = self.bn1(out)\n",
        "\n",
        "    #out = self.a2(out)\n",
        "    \n",
        "    #out = self.relu(out)\n",
        "    #out = self.bn2(out)\n",
        "    out = self.a3(out)\n",
        "    \n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    #torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)"
      ],
      "metadata": {
        "id": "p94V2uI-CC86"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training_network(object):\n",
        "\n",
        "  def __init__(self, assets, epochs = 400, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    \n",
        "    # transform data into tensors \n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double()\n",
        "\n",
        "    self.network.train(True)\n",
        "    ones = torch.ones(len(future_payoff))\n",
        "    losses = []\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      running_loss = 0.0\n",
        "\n",
        "      for batch in tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=self.batch_size, drop_last=False):\n",
        "        optimizer.zero_grad()\n",
        "        with torch.set_grad_enabled(True):\n",
        "          outputs = self.network.forward(X_inputs[batch]).reshape(-1) \n",
        "          reward = (current_payoff[batch].reshape(-1) * outputs + future_payoff[batch] * (ones[batch] - outputs) )\n",
        "\n",
        "          # compute loss function\n",
        "          loss = -torch.mean(reward)\n",
        "\n",
        "          # compute gradients and backpropagate\n",
        "          loss.backward() \n",
        "\n",
        "          # take a step, updating the parameters  \n",
        "          optimizer.step() \n",
        "\n",
        "          running_loss += loss.item() * self.batch_size\n",
        "      epoch_loss = running_loss /  len(tdata.BatchSampler(\n",
        "              tdata.RandomSampler(range(len(X_inputs)), replacement=False),\n",
        "              batch_size=self.batch_size, drop_last=False).sampler)\n",
        "      losses.append(epoch_loss)\n",
        "\n",
        "\n",
        "    torch.save(self.network.state_dict(), 'checkpoint.pth')\n",
        "    return outputs, self.network, losses  \n",
        "\n",
        "  def evaluate_network(self, X_inputs):\n",
        "\n",
        "    # load saved optimized parameters\n",
        "    state_dict = torch.load('checkpoint.pth')\n",
        "    \n",
        "    # impose \"evaluation\" mode\n",
        "    self.network.eval()\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()).detach().numpy(), self.network"
      ],
      "metadata": {
        "id": "ts0bQ6QyCHOk"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Class \"Profit\"\n",
        "This class contains various payoff and costs elements that define the reward. The final profit value is computed for each date and path.\n",
        "\n",
        "### terminal reward\n",
        "The terminal function $\\Gamma_T$ is set to an option payoff function of choice regardless of the regime in which the process is at, in this case we have a Max Call. (other choices can be made as well). The terminal payoff is received at maturity, with no other costs nor payoffs.\n",
        "\\begin{equation}\n",
        "\\Gamma(T) = \\Big(\\max_{d \\in \\{1, \\ldots, D \\}} x^d - K   \\Big)^{+} \\tag{1}\n",
        "\\end{equation}\n",
        "\n",
        "### running reward\n",
        "The function $\\Psi_i = (\\Psi_i(t))_{n \\in \\mathbb{N}}$ represents the running reward received while in mode $q \\in \\mathbb{I}$. \n",
        "\\begin{equation}\n",
        "\\Psi_i(t) = \\Big[\\Big(\\max_{d \\in \\{1, \\ldots, D\\}} x^d - K   \\Big)^{+} \\Big] \\tag{2}\n",
        "\\end{equation}\n",
        "\n",
        "### switching cost\n",
        "The function $\\gamma_{i, j} = (\\gamma_{i, j}(t))_{t \\in \\mathbb{T}}$ with $i,j \\in \\mathbb{I} = \\{0, 1 \\}$ represents the cost for switching from mode $i \\in \\mathbb{I}$ to mode $j \\in \\mathbb{I}$.\n",
        "\\begin{equation} \\tag{3}\n",
        "\\gamma_{0,0} \\equiv \\gamma_{1,1} \\equiv 0 \\\\\n",
        "\\gamma_{0,1}(t) = \\Big(\\max_{d \\in \\{1, \\ldots, D \\}} x^d - K   \\Big)^{+} + \\delta  \\;\\;\\;\\;\\; \\delta \\sim \\mathcal{N}(0,1)   \\\\ \n",
        "\\gamma_{1, 0}(t) = - \\Big(\\max_{d \\in \\{1, \\ldots, D \\}} x^d - K   \\Big)^{+} \n",
        "\\end{equation}\n",
        "\n",
        "### the full expression for the profit\n",
        "The entire expression for the value of the process at each time $n$ can be represented as: \n",
        "\\begin{equation} \\tag{4}\n",
        "\\tilde{Y}_{T}^i = \\Gamma \\mathbf{1}_{\\{\\tau = T\\}} \n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "\\tilde{Y}_{t}^i &= - \\gamma_{i, j}(\\tau) + \\Psi_i(\\tau) + \\mathbb{E}[\\tilde{Y}_{t+1}^i | \\mathcal{F}_t] \\;\\;\\;\\;\\; \\text{if } i \\neq j \\text{,   for    } t=T-1, \\ldots, 0 \\\\\n",
        "&= \\Psi_i(\\tau) + \\mathbb{E}[\\tilde{Y}_{t+1}^i | \\mathcal{F}_t]  \\;\\;\\;\\;\\; \\text{if } i = j \\text{,   for    } t=T-1, \\ldots, 0\n",
        "\\end{aligned}\n",
        "\\end{equation}"
      ],
      "metadata": {
        "id": "foENTegs2ZLR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Profit_training:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "    self.model = model\n",
        "    \n",
        "\n",
        "  def terminal(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def g(self, date,path,X):\n",
        "    max1=np.max(X[int(date) , path , : ]-self.strike)\n",
        "    return np.exp(-self.model.drift*self.model.dt*date)*np.max(max1,0) \n",
        " \n",
        "\n",
        "  def running(self, Y, X):\n",
        "    gamma = np.array([self.terminal(X) + 0.7, -self.terminal(X)]) # there are two rows, the first for \\gamma_{0,1}, the second for \\gamma_{1,0}\n",
        "    r_benefit = self.terminal(X)\n",
        "    return r_benefit+Y-gamma \n",
        " \n",
        "class Profit_testing:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "    self.model = model\n",
        "\n",
        "  def terminal(self, X):\n",
        "    payoff = np.max(X, axis=1) - self.strike\n",
        "    return payoff.clip(0, None)  \n",
        "\n",
        "  def g(self, date,path,X):\n",
        "    max1=np.max(X[date , path , : ]-self.strike)\n",
        "    return np.max(max1,0) \n",
        "\n",
        "\n",
        "  # switch is F_theta_train \n",
        "  def running(self, Y, date, path, S, X, switch, gamma):\n",
        "    val=Y[date+1, path]- gamma  \n",
        "    k = np.array([0.4, 0.7])\n",
        "    r_benefit = self.g(date, path, X)\n",
        "    return val*int(switch[date, path])+r_benefit.numpy()\n",
        "\n",
        "\n",
        "  def current_payoff(self, data, Y, date, regimes, regimepath):\n",
        "    current_p = np.zeros((self.model.paths))\n",
        "    \n",
        "    for m in range(0, self.model.paths - 1):\n",
        "        value = Y[date+1, m]\n",
        "        running_benefit = self.g(date, m, data)      \n",
        "        old_regime = int(regimepath[date +1, m])     \n",
        "        current_regime = int(regimes[~old_regime])\n",
        "\n",
        "        \n",
        "        if (old_regime - current_regime)>0:          #gamma 0-1\n",
        "          gamma = self.g(date, m, data)**0.3+np.random.normal(0,1,1) + value\n",
        "        \n",
        "        else: gamma = - self.g(date, m, data) + value #gamma 1-0  \n",
        "        current_p[m] = gamma + running_benefit\n",
        "        #current_p[m] = gamma + running_benefit\n",
        "            \n",
        "    return current_p\n",
        "\n",
        "  def current_payoff_trained(self, data, Y, date, regimes, regime_path, which): \n",
        "    current_p = np.zeros((self.model.paths))\n",
        "    for m in range(0, self.model.paths - 1):\n",
        "      running_benefit = self.g(date, m, data) \n",
        "      old_regime = int(regime_path[date +1, m])\n",
        "      value = Y[date+1, m]\n",
        "      \n",
        "      if int(which[m])==1:\n",
        "        regime_path[date, m] = regimes[~old_regime]\n",
        "        current_regime = regime_path[date, m]\n",
        "        if (old_regime - current_regime)>0:          \n",
        "          gamma = self.g(date, m, data)**0.3+np.random.normal(0,1,1) + value #gamma 0-1\n",
        "        else: \n",
        "          gamma = - self.g(date, m, data) + value #gamma 1-0  \n",
        "      else:\n",
        "        regime_path[date, m]=int(regimes[~old_regime])\n",
        "        gamma = 0\n",
        "      current_p[m] = gamma + running_benefit\n",
        "    return current_p\n",
        "    "
      ],
      "metadata": {
        "id": "4vdhJjVlyJbF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Training:\n",
        "  def __init__(self, model, payoff):\n",
        "\n",
        "    self.model = model    \n",
        "    self.neural_stopping = Training_network(self.model.assets, 400) \n",
        "    self.payoff = Profit_testing(self.model)\n",
        "\n",
        "  def value(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    \n",
        "    # create empty objects to store values\n",
        "    regimes = [0, 1]\n",
        "    regime_path=np.zeros((model.periods+1, model.paths)) # record at which regime we're at at each n\n",
        "    Y_train=np.zeros((model.periods+1, model.paths))\n",
        "    F_theta_train=np.zeros((model.periods+1,model.paths)) # record switching events for each n\n",
        "    mods=[None]*model.periods # record the models of the NN for testing\n",
        "    loss_functions = [None]*model.periods\n",
        "\n",
        "    # at maturity N\n",
        "    final_payoff = self.payoff.terminal(stock_paths[-1, :, :])   # payoff of the last date for each path.\n",
        "    Y_train[model.periods, :]= final_payoff\n",
        "    F_theta_train[model.periods,:]=1 # at maturity we switch \n",
        "    regime_path[model.periods, :] = random.sample(regimes, 1)[0] # sample a regime at maturity\n",
        "    values = final_payoff\n",
        "    print(\"date\", model.periods, \",\", model.paths)\n",
        "\n",
        "    # before maturity\n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1): \n",
        "      current_payoff = self.payoff.current_payoff(data = stock_paths, \n",
        "                                               Y = Y_train, date = date, \n",
        "                                               regimes = regimes,\n",
        "                                               regimepath = regime_path)\n",
        "\n",
        "      stopping_probability, networks, loss = self.neural_stopping.train_network(stock_paths[date, : , :], \n",
        "                                                    current_payoff, \n",
        "                                                    final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "\n",
        "      \n",
        "      \n",
        "      print(\"date\", date, \",\", len([1 for l in stopping_probability if l > 0.5]), \" mean loss \", np.mean(loss))\n",
        "      F_theta_train[date,:]=(stopping_probability > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "      which = stopping_probability > 0.5\n",
        "      immediate_exercise_value = self.payoff.current_payoff_trained(stock_paths, Y_train, date, regimes, regime_path, which)\n",
        "\n",
        "\n",
        "      values[which] = immediate_exercise_value[which] # when we switch we take the current profit\n",
        "      values[~which] *= np.math.exp((-model.drift) * ((model.periods-date)/model.periods))           # when we don't switch we take final profit discounted \n",
        "      Y_train[date, :] = values\n",
        "\n",
        "      mods[date]=networks \n",
        "      loss_functions[date]=loss    \n",
        "    \n",
        "    return mods, loss_functions\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "  def stop(self, stock_values, current_payoff,\n",
        "           future_payoff):\n",
        "    \n",
        "    self.neural_stopping.train_network(\n",
        "      stock_values,\n",
        "      current_payoff ,\n",
        "      future_payoff)\n",
        "\n",
        "    inputs = stock_values\n",
        "    stopping_probability , networks   = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability , networks  \n"
      ],
      "metadata": {
        "id": "7UvqI1aXKWAL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simulate paths Y\n",
        "# goal of this phase is to be able to get stopping decisions f_theta_n\n",
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':200, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_train=BlackScholes(**hyperparam_training)\n",
        "\n",
        "\n",
        "pricing = Training(S_train, Profit_testing)\n",
        "'''\n",
        "arguments are:\n",
        "- path process\n",
        "- Profit testing classes\n",
        "\n",
        "\n",
        "'''\n",
        "\n",
        "mods, functions = pricing.value()\n"
      ],
      "metadata": {
        "id": "sp-KE2XpKsKY",
        "outputId": "1608677b-1ebd-4e8e-8bfb-3b2d27fcb2b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 9 , 200\n",
            "date 8 , 186  mean loss  -493.1139946334242\n",
            "date 7 , 196  mean loss  -506.75732664416296\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: RuntimeWarning: invalid value encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date 6 , 0  mean loss  nan\n",
            "date 5 , 0  mean loss  nan\n",
            "date 4 , 0  mean loss  nan\n",
            "date 3 , 0  mean loss  nan\n",
            "date 2 , 0  mean loss  nan\n",
            "date 1 , 0  mean loss  nan\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_list = list(filter(None, functions))\n",
        "legend = [\"n = 1\", \"n = 2\", \"n = 3\", \"n = 4\", \"n = 5\", \"n = 6\", \"n = 7\", \"n = 8\"]\n",
        "\n",
        "for i in range(len(filtered_list)):\n",
        "  epochs = np.array([i for i in range(len(filtered_list[0]))])\n",
        "  plt.plot(epochs, filtered_list[i], label='loss funciton')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend(legend)\n",
        "  plt.title('Loss curves across time periods')\n",
        "  plt.plot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "yVXeiEjqrfRf",
        "outputId": "8d225c4e-c36d-4edc-b66a-e067f1d02a17"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Lower bound\n",
        "\n",
        "the stopping time $\\tau^{\\Theta}$ gives a lower bound $L=\\mathbb{E}g(\\tau^{\\Theta}, X_{\\tau^{\\Theta}})$ for the optimal value $V_0= \\sup_{\\tau \\in \\mathcal{T}}\\mathbb{E}g(\\tau, X_{\\tau})$.\n",
        "\n",
        "Simulate \n",
        "- $K_L = 1024$ paths $(y_n^k)_{n=0}^N$, $k=1, \\ldots, K_L$, of $(X_n)_{n=0}^N$ and assume these are drawn independently from the realizations $(x_n^k)_{n=0}^N$, $k=1, \\ldots, K$.\n",
        "\n",
        "The unbiased estimate of the lower bound $L$ is given by\n",
        "\\begin{equation}\n",
        "\\hat{L}=\\frac{1}{K_L} \\sum_{k=1}^{K_L} g(l^k, y_{l^k}^k)\n",
        "\\end{equation}\n",
        "where $l^k = l(y_0^k, \\ldots, y_{N-1}^k)$"
      ],
      "metadata": {
        "id": "k8JSTFLsNMD8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing phase - Lower bound\n",
        "\n",
        "# sample y from the process (Y)\n",
        "hyperparam_testing_L = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':5000, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':20,  'spot':110,}\n",
        "S_test_L=BlackScholes(**hyperparam_testing_L)\n",
        "\n",
        "# now we can compute all the stopping times recursively"
      ],
      "metadata": {
        "id": "eBdQnHLJNOMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing\n",
        "\n",
        "class Testing_Lower:\n",
        "  def __init__(self, model, training, testing, mods):   \n",
        "    self.model = model # argument is S   \n",
        "    self.neural_stopping = Training_network(model.assets, 400) \n",
        "    self.profit_testing = Profit_testing(self.model)\n",
        "    self.mods = mods\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    stock_paths = self.model.simulate_process()\n",
        "    k = np.array([0.4, 0.7])\n",
        "    regimes = [0, 1]\n",
        "    regime_path=np.zeros((model.periods+1, model.paths)) # record at which regime we're at at each n\n",
        "    Y_train=np.zeros((model.periods+1, model.paths))\n",
        "    F_theta_train=np.zeros((model.periods+1,model.paths)) # record switching events for each n\n",
        " \n",
        "    # at maturity N\n",
        "    final_payoff = np.array([self.profit_training.terminal(stock_paths[-1, :, :]), self.profit_training.terminal(stock_paths[-1, :, :])])   # payoff of the last date for each path.\n",
        "    future_payoff = torch.from_numpy(final_payoff*(np.math.exp((-model.drift) * model.periods))).double() \n",
        "    Y_train[model.periods, :]= final_payoff[0]\n",
        "    F_theta_train[model.periods,:]=1 # at maturity we switch (does it matter?)\n",
        "    regime_path[model.periods, :] = random.sample(regimes, 1)[0] # sample a regime at maturity\n",
        "    values = Y_train[model.periods, :]\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "    # recursive calc. before maturity\n",
        "         \n",
        "    for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "      current_payoff = self.profit_training.running(Y_train[date+1, :], stock_paths[date, :, :])\n",
        "      mod_curr=self.mods[date]\n",
        "      probs=mod_curr(torch.from_numpy(stock_paths[date])) \n",
        "      np_probs=probs.detach().numpy().reshape(self.model.paths)\n",
        "      \n",
        "      F_theta_train[date,:]=(np_probs > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "      which = np_probs > 0.5\n",
        "\n",
        "      for m in range(0,model.paths-1):\n",
        "        old_regime = regime_path[date +1, m]\n",
        "        regime_path[date, m] = int(which[m])\n",
        "        if which[m] == True:\n",
        "          if int(old_regime) - int(which[m])>0:  #gamma 0-1\n",
        "            gamma = self.profit_testing.g(date, m, stock_paths)+0.7\n",
        "          else: gamma = -self.profit_testing.g(date, m, stock_paths) #gamma 1-0  \n",
        "        else:\n",
        "          gamma = 0 \n",
        "        Y_train[date, m] = Y_train[date+1, m]- gamma\n",
        "\n",
        "\n",
        "      immediate_exercise_value = Y_train[date, :]       \n",
        "      values[which] = immediate_exercise_value[which] # when we switch we take the current profit\n",
        "      values[~which] *= ((model.periods-date)/model.periods)           # when we don't switch we take final profit discounted \n",
        "\n",
        "      #Y_train[date, :] = values\n",
        "      print(\"date\", date, round(np.mean(values), 3), len([1 for l in np_probs if l > 0.5]))\n",
        "\n",
        "    \n",
        "    return round(np.mean(values), 3), Y_train\n",
        "\n"
      ],
      "metadata": {
        "id": "PpoI_K_MNO6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dict ={}\n",
        " \n",
        "# Insert data into dictionary\n",
        "dict1 = {\n",
        "     1: [\"2\", 90, 97.339, 0.009],\n",
        "     2: [\"2\", 100, 205.426, 0.006],\n",
        "     3: [\"2\", 110, 315.878, 0.007],\n",
        "     7: [\"4\", 90, 130.082, 0.008],\n",
        "     8: [\"4\", 100, 235.951, 0.008],\n",
        "     9: [\"4\", 110, 334.079, 0.005],\n",
        "     10: [\"5\", 90, 134.486, 0.008],\n",
        "     11: [\"5\", 100, 224.051, 0.006],\n",
        "     12: [\"5\", 110, 282.737, 0.006],\n",
        "     13: [\"10\", 90, 158.875, 0.005],\n",
        "     14: [\"10\", 100, 273.452, 0.008],\n",
        "     15: [\"10\", 110, 391.043, 0.015],\n",
        "     16: [\"20\", 90, 100.447, 0.008],\n",
        "     17: [\"20\", 100, 192.448, 0.01],\n",
        "     18: [\"20\", 110, 301.107, 0.009],\n",
        "     }\n",
        " \n",
        "# Print the names of the columns.\n",
        "print (\"{:<10} {:<10} {:<10} {:<10}\".format('assets', 'spot', 'L', 'timeL'))\n",
        " \n",
        "# print each data item.\n",
        "for key, value in dict1.items():\n",
        "    assets, spot, L, timeL = value\n",
        "    print (\"{:<10} {:<10} {:<10} {:<10}\".format(assets, spot, L, timeL))"
      ],
      "metadata": {
        "id": "qsGOwzwDvUCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}