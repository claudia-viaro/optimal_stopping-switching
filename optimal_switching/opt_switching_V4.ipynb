{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "opt_switching_V4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPGZ1oR+uw/sQfMjmMpVfUf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudia-viaro/optimal_stopping-switching/blob/main/opt_switching_V4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose we consider both possible final regimes of the process"
      ],
      "metadata": {
        "id": "xAtXzBgLLgwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation\n",
        "Let $(\\Omega, \\mathcal{F}, P)$ be a fixed probability space on which an adapted stochastic process is defined $X=(X_t)_{0 \\leq t \\leq T}$ whose natural filtration is $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. Let $\\mathbf{F}=(\\mathcal{F}_0)_{0 \\leq t \\leq t}$ be the complete filtration of $(\\mathcal{F}_t^0 := \\sigma \\{ X_s, s \\leq t \\})_{0 \\leq t \\leq T}$. with $P$-null sets of $\\mathcal{F}$.\n",
        "\n",
        "The stochastic process $X$ is $\\mathbb{R}^d$-valued and represents the market price of $d$ financial assets (Bermudan call options) that influence the production of power. Assume $(X^i)_{i=1}^d$ follows a geometric Brownian motion satisfying the SDE:\n",
        "\\begin{equation}\n",
        "dX_t = b_{I_t}X_tdt + \\sigma_{I_t}X_tdW_t\n",
        "\\end{equation}\n",
        "where $W$ is a standard Brownian otion on a filtered probability space $(\\Omega, \\mathcal{F}, \\mathbf{F}=(\\mathcal{F}_t)_{t \\geq 0} P)$ and $I_t$ is the indicator variable of the regimes valued in $\\mathbf{I}_d = \\{1, \\ldots, d \\}$. $b_i \\in \\mathbf{R}$ and $\\sigma_i >0$ are the drift and volatility of the system $X$ once in regime $I_t=i$ at time $t$.\n",
        "\n",
        "We will consider a discrete approximization (Euler schema) with respect to. For $i = 1, \\ldots, d$ we simulate $p$ paths\n",
        "\\begin{equation}\n",
        "X^p_{n,i} = \\exp \\Big\\{ \\sum_{k=0}^n \\big( (b-\\sigma^2_i /2)_{\\mathbf{I}}\\bigtriangleup t + \\sigma_{i, \\mathbf{I}} \\sqrt{\\bigtriangleup t} \\cdot Z_{k, i}^p \\big)     \\Big\\}\n",
        "\\end{equation}\n",
        "where $\\bigtriangleup t = T/N$ and $Z_{k, i}^{p} \\sim \\mathcal{N} (0,1)$.\n",
        "\n"
      ],
      "metadata": {
        "id": "Zc3-xlOQ6pf8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3tK6JCs9Fidl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "np.random.seed(234198)\n",
        "import itertools\n",
        "import random\n",
        "import time\n",
        "import scipy.stats\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as tdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BlackScholes:\n",
        "  def __init__(self, drift, sigma, delta, spot, assets,  paths, periods,\n",
        "         maturity, strike, dividend=0):\n",
        "\n",
        "    self.drift = drift - dividend\n",
        "    self.sigma = sigma\n",
        "    self.delta = delta\n",
        "    self.spot = spot\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.periods = periods\n",
        "    self.maturity = maturity\n",
        "    self.strike = strike\n",
        "    self.dt = self.maturity / self.periods\n",
        "    self.df = math.exp(-self.drift * self.dt)\n",
        "\n",
        "  def drift_fct(self, x, t):\n",
        "    del t\n",
        "    return self.drift * x\n",
        "\n",
        "  def diffusion_fct(self, x, t, v=0):\n",
        "    del t\n",
        "    return self.sigma * x\n",
        "\n",
        "\n",
        "\n",
        "  def simulate_process(self):\n",
        "    \"\"\"Returns a nparray (nb_paths * assets * nb_dates) with prices.\"\"\"\n",
        "    paths = self.paths\n",
        "    spot_paths = np.empty((self.periods+1, paths, self.assets ))\n",
        "\n",
        "    spot_paths[0, :, :] = self.spot\n",
        "    random_numbers = np.random.normal(\n",
        "        0, 1, (self.periods, paths, self.assets ))\n",
        "    dW = random_numbers * np.sqrt(self.dt)\n",
        "    drift = self.drift\n",
        "    r = np.repeat(np.repeat(np.repeat(\n",
        "        np.reshape(drift, (-1, 1, 1)), self.periods, axis=0),\n",
        "        paths, axis=1), self.assets, axis=2)\n",
        "    sig = np.ones((self.periods, paths, self.assets))*self.sigma\n",
        "    #sig = np.repeat(np.repeat(np.repeat(\n",
        "    #    np.reshape(self.sigma, (-1, 1, 1)), self.periods+1, axis=2),\n",
        "    #    paths, axis=1), self.assets, axis=0)\n",
        "    \n",
        "    spot_paths[1:, :,  :] = np.repeat(\n",
        "        spot_paths[0:1, :, :], self.periods, axis=0)* np.exp(np.cumsum((r-self.delta) * self.dt - (sig ** 2) * self.dt / 2 + sig * dW, axis=0))\n",
        "\n",
        "    return spot_paths #.reshape(spot_paths.shape[2], spot_paths.shape[0], spot_paths.shape[1])\n",
        "\n",
        "\n",
        "'''\n",
        "PLOT\n",
        "'''\n",
        "\n",
        "def draw_stock_model(stockmodel):\n",
        "    stock_paths = stockmodel\n",
        "\n",
        "    # draw a path\n",
        "    one_path = stock_paths[:, 0, 0]\n",
        "    dates = np.array([i for i in range(len(one_path))])\n",
        "    plt.plot(dates, one_path, label='stock path')\n",
        "    plt.ylabel('Stock price')\n",
        "    plt.ylabel('Time')\n",
        "    plt.legend()\n",
        "    return plt.show()\n",
        "\n",
        "\n",
        "\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    H = assets + 40\n",
        "    self.bn0 = nn.BatchNorm1d(num_features=assets)\n",
        "    self.layer1 = nn.Linear(assets, H)\n",
        "    self.leakyReLU = nn.LeakyReLU(0.5)\n",
        "    self.Softplus = nn.Softplus()\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    self.tanh = nn.Tanh()\n",
        "    self.relu = nn.ReLU()\n",
        "    self.bn1 = nn.BatchNorm1d(num_features=H)\n",
        "    self.layer2 = nn.Linear(H, H)\n",
        "    self.bn2 = nn.BatchNorm1d(num_features=H)\n",
        "    self.layer3 = nn.Linear(H, 1)\n",
        "    self.bn3 = nn.BatchNorm1d(num_features=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn0(x)\n",
        "    x = self.layer1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.layer3(x)\n",
        "    x = self.sigmoid(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "class Ftheta_NN(nn.Module):\n",
        "  def __init__(self, assets, hidden_size):\n",
        "    super(Ftheta_NN, self).__init__()\n",
        "    self.l1 = nn.Linear(assets, hidden_size) \n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, hidden_size)\n",
        "    self.l3 = nn.Linear(hidden_size, 1)  \n",
        "    self.sigmoid=nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    out = self.relu(out)\n",
        "    out = self.l3(out)\n",
        "    out = self.sigmoid(out)\n",
        "    return out\n",
        "'''\n",
        "# set initial weights of a linear layer of the NN with uniform values and bias=0.01 (or choose zero initial weights)\n",
        "def init_weights(m):\n",
        "  if isinstance(m, torch.nn.Linear):\n",
        "    torch.manual_seed(42)\n",
        "    # torch.nn.init.zeros_(m.weight)\n",
        "    torch.nn.init.xavier_uniform_(m.weight)\n",
        "    m.bias.data.fill_(0.01)\n"
      ],
      "metadata": {
        "id": "DqtK6h69Fkp4"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Profit:\n",
        "  def __init__(self, model):\n",
        "    self.strike = model.strike\n",
        "    self.model = model\n",
        "  '''  \n",
        "  def terminal_(self, X):\n",
        "    terminal = np.max(X, axis=1) - self.strike\n",
        "    return terminal.clip(0, None)\n",
        "  '''\n",
        "  def g(self, date,path,X):\n",
        "    X=torch.from_numpy(X).float()\n",
        "    max1=torch.max(X[int(date) , path , : ].float()-self.strike)\n",
        "    return torch.max(max1,torch.tensor([0.0])) \n",
        "\n",
        "\n",
        "  def terminal(self, X):\n",
        "    payoff = np.max(X) - self.strike\n",
        "    return payoff.clip(0, None)\n",
        "\n",
        "  def running(self, Y, X, switch_to):\n",
        "    \n",
        "    r_benefit = self.terminal(X)\n",
        "    for i in range(0, self.model.paths):\n",
        "      if switch_to[i] == 0:\n",
        "        gamma = -self.terminal(X[i]) # there are two rows, the first for \\gamma_{0,1}, the second for \\gamma_{1,0}\n",
        "      else:\n",
        "        gamma: self.terminal(X[i]) + 0.7  \n",
        "\n",
        "    return torch.from_numpy(r_benefit+Y-gamma)  \n",
        "\n",
        "  def current_payoff(self, X, Y, regime_path):\n",
        "  # X is stock_paths[date, :, :]\n",
        "  # Y is Y_train_i[date+1, :] or Y_train_j\n",
        "  # regime_path is regime_path_i[date+1, :]\n",
        "  \n",
        "    current_payoff = np.zeros((self.model.paths))\n",
        "    \n",
        "    for i in range(0, self.model.paths):\n",
        "      if int(regime_path[i]) == 0:\n",
        "        gamma = 0                    #-self.terminal(X[i, :])\n",
        "      else:\n",
        "        gamma= self.terminal(X[i, :]) + 0.7  \n",
        "      current_payoff[i]=-gamma+Y[i]    #self.terminal(X[i, :])\n",
        "\n",
        "    return current_payoff   \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "wtfGw1amGAwh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Optimization(object):\n",
        "\n",
        "  def __init__(self, assets, paths, epochs=50, batch_size=2000):\n",
        "    self.assets = assets\n",
        "    self.paths = paths\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.network = Ftheta_NN(self.assets).double()\n",
        "    self.network.apply(init_weights)\n",
        "\n",
        "\n",
        "  def train_network(self,  stock_values, current_payoff,\n",
        "                    future_payoff):\n",
        "    optimizer = optim.Adam(self.network.parameters())\n",
        "    future_payoff = torch.from_numpy(future_payoff).double()\n",
        "    current_payoff = torch.from_numpy(current_payoff).double()\n",
        "    X_inputs = torch.from_numpy(stock_values).double()\n",
        "\n",
        "    self.network.train(True)\n",
        "    ones = torch.ones(self.paths)\n",
        "    for epoch in range(self.epochs):\n",
        "      optimizer.zero_grad()\n",
        "      outputs = self.network(X_inputs).reshape(-1) # probabilities\n",
        "      reward = (current_payoff * outputs ) +future_payoff * (ones - outputs) # reward function\n",
        "      loss = -torch.mean(reward) # loss function\n",
        "      loss.backward() # gradient calculation of the loss function\n",
        "      optimizer.step() # gradient descent update\n",
        "\n",
        "  def evaluate_network(self, X_inputs):\n",
        "    self.network.train(False)\n",
        "    X_inputs = torch.from_numpy(X_inputs).double()\n",
        "    outputs = self.network(X_inputs)\n",
        "    return outputs.view(X_inputs.size()[0]).detach().numpy(), self.network"
      ],
      "metadata": {
        "id": "25OHkXSYGCle"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# i=0, j=1\n",
        "\n",
        "class Training_large:\n",
        "  def __init__(self, model, payoff, nb_epochs=50):\n",
        "\n",
        "    self.model = model # argument is S    \n",
        "    self.neural_stopping = Optimization(self.model.assets, self.model.paths) \n",
        "    self.payoff_function = payoff(self.model)\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    stock_paths = self.model.simulate_process()    \n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    \n",
        "    # create empty objects to store values\n",
        "    models = [None]*self.model.periods, [None]*self.model.periods\n",
        "\n",
        "    regimes = [0, 1]\n",
        "    regime_path_i=np.zeros((self.model.periods+1, self.model.paths)) # record at which regime we're at at each n\n",
        "    regime_path_j=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    regimes_path=np.array([regime_path_i, regime_path_j]) #you can call each regime by regimes_path[0]\n",
        "\n",
        "    Y_train_i=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    Y_train_j=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    Y_train = np.array([Y_train_i, Y_train_j])\n",
        "\n",
        "    F_theta_i=np.zeros((self.model.periods+1,self.model.paths))\n",
        "    F_theta_j=np.zeros((self.model.periods+1,self.model.paths))\n",
        "    F_theta=np.array([F_theta_i, F_theta_j])\n",
        "    F_theta[1][self.model.periods, 0:self.model.paths] = 1\n",
        "\n",
        "    values = np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "\n",
        "    # at n=N\n",
        "    final_payoff = np.array([self.payoff_function.terminal(stock_paths[-1, :, :])])\n",
        "    future_payoff = final_payoff*disc_factor\n",
        "\n",
        "\n",
        "    for r in regimes:\n",
        "      # still at maturity\n",
        "      Y_train[r][self.model.periods, :]=final_payoff\n",
        "      regimes_path[r][self.model.periods, :] = regimes[r]\n",
        "      values[r] = Y_train[r][self.model.periods, :]\n",
        "      print(\"final regime\", r, \"date\", self.model.periods, \":\", 1.00,\" , \", 1.00, \" , \", self.model.paths, \"value\", round(np.mean(values[r]),3))\n",
        "\n",
        "      for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "        current_payoff = np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "        current_payoff[r] = self.payoff_function.current_payoff(stock_paths[date, :, :], Y_train[r][date+1, :], regimes_path[r][date+1, :])\n",
        "        stopping_probability=np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "        Nnetworks=np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "        stopping_probability[r], models[r][date] = self.stop(stock_paths[date, : , :], \n",
        "                                    current_payoff[r],\n",
        "                                    final_payoff*(np.math.exp((-model.drift) * (model.periods-date)/model.periods)))\n",
        "        \n",
        "        F_theta[r][date,:]=(stopping_probability[r] > 0.5)*1.00   # transform stopping probabilities in 0-1 decision\n",
        "        #which_i = stopping_probability_i > 0.5\n",
        "\n",
        "        for m in range(0,self.model.paths-1):\n",
        "          old_regime = regimes_path[r][date +1, m]\n",
        "          regimes_path[r][date, m] = int(F_theta[r][date,m])   #int(which_i[m])   #current regime using probabilities just obtained\n",
        "\n",
        "          if int(old_regime) - regimes_path[r][date, m]>0:  #gamma 0-1\n",
        "            gamma = self.payoff_function.g(date, m, stock_paths)+0.7\n",
        "          elif int(old_regime) - regimes_path[r][date, m]<0: \n",
        "            gamma = - self.payoff_function.g(date, m, stock_paths) #gamma 1-0  \n",
        "          else:\n",
        "            gamma = 0 \n",
        "          Y_train[r][date, m] = Y_train[r][date+1, m]- gamma\n",
        "\n",
        "        immediate_exercise_value = Y_train[r][date, :]       \n",
        "        values[r][int(regimes_path[r][date, m])] = immediate_exercise_value[int(regimes_path[r][date, m])] # when we switch we take the current profit\n",
        "        values[r][~int(regimes_path[r][date, m])] *= np.math.exp((-model.drift) * ((model.periods-date)/model.periods))           # when we don't switch we take final profit discounted \n",
        "        print(\"final regime\", r, \"date\", date, \":\", round(np.min(stopping_probability[r]), 3),\" , \", round(np.max(stopping_probability[r]), 3), \" , \", len([1 for l in stopping_probability[r] if l > 0.5]), \"value\", round(np.mean(values[r]),3))          \n",
        "\n",
        "\n",
        "    return models\n",
        "\n",
        "  def stop(self, stock_values, current_payoff,\n",
        "           future_payoff):\n",
        "     \n",
        "    self.neural_stopping.train_network(\n",
        "      stock_values,\n",
        "      current_payoff ,\n",
        "      future_payoff)\n",
        "\n",
        "    inputs = stock_values\n",
        "    stopping_probability , networks   = self.neural_stopping.evaluate_network(inputs)\n",
        "    return stopping_probability , networks  "
      ],
      "metadata": {
        "id": "s7id_0bEGGMm"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_training = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':5000, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_training=BlackScholes(**hyperparam_training)\n",
        "\n",
        "\n",
        "Price_training = Training_large(S_training, Profit, nb_epochs=3000)\n",
        "\n",
        "'''\n",
        "arguments are:\n",
        "- path process\n",
        "- payoff class of functions\n",
        "- number of epochs to be used for the gradient descent algorithm\n",
        "'''\n",
        "\n",
        "Models = Price_training.price()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gU4v0ICIGKaE",
        "outputId": "1e16511d-e044-4428-8f31-554bf98ac666"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final regime 0 date 9 : 1.0  ,  1.0  ,  5000 value 70.08\n",
            "final regime 0 date 8 : 0.0  ,  0.937  ,  3872 value 70.08\n",
            "final regime 0 date 7 : 0.0  ,  0.991  ,  4151 value 70.079\n",
            "final regime 0 date 6 : 0.0  ,  0.991  ,  4544 value 70.079\n",
            "final regime 0 date 5 : 0.0  ,  0.993  ,  4819 value 70.078\n",
            "final regime 0 date 4 : 0.0  ,  0.995  ,  4960 value 70.077\n",
            "final regime 0 date 3 : 0.0  ,  0.999  ,  4977 value 70.075\n",
            "final regime 0 date 2 : 0.997  ,  1.0  ,  5000 value 70.074\n",
            "final regime 0 date 1 : 0.0  ,  1.0  ,  4999 value 70.073\n",
            "final regime 1 date 9 : 1.0  ,  1.0  ,  5000 value 70.08\n",
            "final regime 1 date 8 : 0.0  ,  1.0  ,  4465 value 70.08\n",
            "final regime 1 date 7 : 0.0  ,  1.0  ,  3528 value 70.079\n",
            "final regime 1 date 6 : 0.0  ,  1.0  ,  2903 value 70.078\n",
            "final regime 1 date 5 : 0.0  ,  1.0  ,  2338 value 70.077\n",
            "final regime 1 date 4 : 0.0  ,  1.0  ,  1905 value 70.076\n",
            "final regime 1 date 3 : 0.0  ,  1.0  ,  1688 value 70.074\n",
            "final regime 1 date 2 : 0.0  ,  1.0  ,  1790 value 70.073\n",
            "final regime 1 date 1 : 0.0  ,  1.0  ,  1982 value 70.072\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# testing bound\n",
        "\n",
        "class Testing_large:\n",
        "  def __init__(self, model, payoff, models):   \n",
        "    self.model = model # argument is S   \n",
        "    self.neural_stopping = Optimization(model.assets, model.paths) \n",
        "    self.payoff_function = payoff(self.model)\n",
        "    self.models = models\n",
        "\n",
        "  def price(self):\n",
        "    model = self.model\n",
        "    disc_factor = np.math.exp((-model.drift) * model.maturity/(model.periods))\n",
        "    stock_paths = self.model.simulate_process()\n",
        "\n",
        "\n",
        "    # create empty objects to store values\n",
        "\n",
        "    regimes = [0, 1]\n",
        "    regime_path_i=np.zeros((self.model.periods+1, self.model.paths)) # record at which regime we're at at each n\n",
        "    regime_path_j=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    regimes_path=np.array([regime_path_i, regime_path_j]) #you can call each regime by regimes_path[0]\n",
        "\n",
        "    Y_train_i=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    Y_train_j=np.zeros((self.model.periods+1, self.model.paths))\n",
        "    Y_train = np.array([Y_train_i, Y_train_j])\n",
        "\n",
        "    F_theta_i=np.zeros((self.model.periods+1,self.model.paths))\n",
        "    F_theta_j=np.zeros((self.model.periods+1,self.model.paths))\n",
        "    F_theta=np.array([F_theta_i, F_theta_j])\n",
        "    F_theta[1][self.model.periods, 0:self.model.paths] = 1\n",
        "\n",
        "    values = np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "\n",
        "    # at n=N\n",
        "    final_payoff = np.array([self.payoff_function.terminal(stock_paths[-1, :, :])])\n",
        "\n",
        "    for r in regimes:\n",
        "      # still at maturity\n",
        "      Y_train[r][self.model.periods, :]=final_payoff\n",
        "      regimes_path[r][self.model.periods, :] = regimes[r]\n",
        "      values[r] = Y_train[r][self.model.periods, :]\n",
        "      print(\"final regime\", r, \"date\",  self.model.periods, \":\", round(np.mean(values[r]),3))\n",
        "\n",
        "      for date in range(stock_paths.shape[0] - 2, 0, -1):\n",
        "        current_payoff = np.array([np.zeros(self.model.paths), np.zeros(self.model.paths)])\n",
        "        current_payoff[r] = self.payoff_function.current_payoff(stock_paths[date, :, :], Y_train[r][date+1, :], regimes_path[r][date+1, :])\n",
        "        current_model=self.models[r][date]\n",
        "        probs=current_model(torch.from_numpy(stock_paths[date])) \n",
        "        np_probs=probs.detach().numpy().reshape(self.model.paths)\n",
        "      \n",
        "        F_theta[r][date,:]=(np_probs > 0.5)*1.0   # transform stopping probabilities in 0-1 decision\n",
        "        #which = np_probs > 0.5        \n",
        "        \n",
        "\n",
        "        for m in range(0,self.model.paths-1):\n",
        "          old_regime = regimes_path[r][date +1, m]\n",
        "          regimes_path[r][date, m] = int(F_theta[r][date,m])   #int(which_i[m])   #current regime using probabilities just obtained\n",
        "\n",
        "          if int(old_regime) - regimes_path[r][date, m]>0:  #gamma 0-1\n",
        "            gamma = self.payoff_function.g(date, m, stock_paths)+0.7\n",
        "          elif int(old_regime) - regimes_path[r][date, m]<0: \n",
        "            gamma = - self.payoff_function.g(date, m, stock_paths) #gamma 1-0  \n",
        "          else:\n",
        "            gamma = 0 \n",
        "          Y_train[r][date, m] = Y_train[r][date+1, m]- gamma\n",
        "\n",
        "        immediate_exercise_value = Y_train[r][date, :]       \n",
        "        values[r][int(regimes_path[r][date, m])] = immediate_exercise_value[int(regimes_path[r][date, m])] # when we switch we take the current profit\n",
        "        values[r][~int(regimes_path[r][date, m])] *= ((model.periods-date)/model.periods)            # when we don't switch we take final profit discounted \n",
        "        print(\"final regime\", r, \"date\", date, \":\", round(np.mean(values[r]),3))          \n",
        "\n",
        "\n",
        "    return round(np.mean(values)* disc_factor, 3), Y_train"
      ],
      "metadata": {
        "id": "H1adTO26GREl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparam_testing = {'drift': 0.2, 'sigma': 0.05, 'delta': 0.1,  'paths':50000, 'periods': 9, 'maturity': 3., 'strike' : 100,'assets':2,  'spot':90,}\n",
        "S_testing=BlackScholes(**hyperparam_testing)"
      ],
      "metadata": {
        "id": "THcI7TzFJM3G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "price_testing = Testing_large(S_testing, Profit, Models)\n",
        "\n",
        "Y_test_mean, Y_train = price_testing.price()\n",
        "print(Y_test_mean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ssl7gcThJouF",
        "outputId": "1deae732-2b6e-4b3a-faed-733f47fcebbc"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "final regime 0 date 9 : 84.425\n",
            "final regime 0 date 8 : 84.424\n",
            "final regime 0 date 7 : 84.424\n",
            "final regime 0 date 6 : 84.424\n",
            "final regime 0 date 5 : 84.424\n",
            "final regime 0 date 4 : 84.424\n",
            "final regime 0 date 3 : 84.424\n",
            "final regime 0 date 2 : 84.424\n",
            "final regime 0 date 1 : 84.423\n",
            "final regime 1 date 9 : 84.425\n",
            "final regime 1 date 8 : 84.423\n",
            "final regime 1 date 7 : 84.423\n",
            "final regime 1 date 6 : 84.423\n",
            "final regime 1 date 5 : 84.423\n",
            "final regime 1 date 4 : 84.423\n",
            "final regime 1 date 3 : 84.423\n",
            "final regime 1 date 2 : 84.423\n",
            "final regime 1 date 1 : 84.423\n",
            "78.978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dict ={}\n",
        " \n",
        "# Insert data into dictionary\n",
        "dict1 = {\n",
        "     1: [\"2\", 90, 97.339, 0.009],\n",
        "     2: [\"2\", 100, 205.426, 0.006],\n",
        "     3: [\"2\", 110, 315.878, 0.007],\n",
        "     7: [\"4\", 90, 130.082, 0.008],\n",
        "     8: [\"4\", 100, 235.951, 0.008],\n",
        "     9: [\"4\", 110, 334.079, 0.005],\n",
        "     10: [\"5\", 90, 134.486, 0.008],\n",
        "     11: [\"5\", 100, 224.051, 0.006],\n",
        "     12: [\"5\", 110, 282.737, 0.006],\n",
        "     13: [\"10\", 90, 158.875, 0.005],\n",
        "     14: [\"10\", 100, 273.452, 0.008],\n",
        "     15: [\"10\", 110, 391.043, 0.015],\n",
        "     16: [\"20\", 90, 100.447, 0.008],\n",
        "     17: [\"20\", 100, 192.448, 0.01],\n",
        "     18: [\"20\", 110, 301.107, 0.009],\n",
        "     }\n",
        " \n",
        "# Print the names of the columns.\n",
        "print (\"{:<10} {:<10} {:<10} {:<10}\".format('assets', 'spot', 'L', 'timeL'))\n",
        " \n",
        "# print each data item.\n",
        "for key, value in dict1.items():\n",
        "    assets, spot, L, timeL = value\n",
        "    print (\"{:<10} {:<10} {:<10} {:<10}\".format(assets, spot, L, timeL))"
      ],
      "metadata": {
        "id": "rNaQFLLw8tp8",
        "outputId": "34ebdf7f-e16b-47c2-a55c-d6e2a3182d55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets     spot       L          timeL     \n",
            "2          90         97.339     0.009     \n",
            "2          100        205.426    0.006     \n",
            "2          110        315.878    0.007     \n",
            "4          90         130.082    0.008     \n",
            "4          100        235.951    0.008     \n",
            "4          110        334.079    0.005     \n",
            "5          90         134.486    0.008     \n",
            "5          100        224.051    0.006     \n",
            "5          110        282.737    0.006     \n",
            "10         90         158.875    0.005     \n",
            "10         100        273.452    0.008     \n",
            "10         110        391.043    0.015     \n",
            "20         90         100.447    0.008     \n",
            "20         100        192.448    0.01      \n",
            "20         110        301.107    0.009     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_train[0])"
      ],
      "metadata": {
        "id": "pTx6GPGd9Bf6",
        "outputId": "559653b1-c75e-4ebc-b534-f000c588e9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [84.42537013 84.42536926 84.42537013 ... 84.42537013 84.42536926\n",
            "   0.        ]\n",
            " [84.42537013 84.42537013 84.42537013 ... 84.42537013 84.42537013\n",
            "   0.        ]\n",
            " ...\n",
            " [84.42537013 84.42537013 84.42537013 ... 84.42537013 84.42537013\n",
            "   0.        ]\n",
            " [84.42537013 84.42537013 84.42537013 ... 84.42537013 84.42537013\n",
            "   0.        ]\n",
            " [84.42537013 84.42537013 84.42537013 ... 84.42537013 84.42537013\n",
            "  84.42537013]]\n"
          ]
        }
      ]
    }
  ]
}
